ðŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 8.9.1 Polling et long-polling : principes et limites

## Introduction

Le polling et le long-polling sont les **techniques les plus anciennes et les plus simples** pour simuler une communication temps rÃ©el sur le web. Bien qu'aujourd'hui largement supplantÃ©es par SSE et WebSocket pour les nouveaux projets, elles restent **omniprÃ©sentes** dans l'Ã©cosystÃ¨me web pour trois raisons :

1. **CompatibilitÃ© universelle** : Fonctionnent partout, mÃªme avec les proxies/firewalls les plus restrictifs
2. **SimplicitÃ©** : Peuvent Ãªtre implÃ©mentÃ©es en quelques lignes de code
3. **Legacy** : Des millions d'applications existantes les utilisent encore

**Ce que vous apprendrez** :
- Comment implÃ©menter correctement le polling et long-polling
- Quand (et surtout quand ne pas) les utiliser
- Les piÃ¨ges et optimisations essentiels
- Comment migrer vers des solutions modernes

---

## Short Polling (Polling classique)

### Principe fondamental

Le **short polling** est la technique la plus basique : le client interroge pÃ©riodiquement le serveur Ã  intervalles rÃ©guliers, que les donnÃ©es aient changÃ© ou non.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SHORT POLLING : Timeline               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  t=0s    Client â”€â”€GET /api/messagesâ”€â”€> Serveur      â”‚
â”‚          Client <â”€â”€200 OK (vide)â”€â”€â”€â”€â”€â”€ Serveur      â”‚
â”‚                                                     â”‚
â”‚  t=5s    Client â”€â”€GET /api/messagesâ”€â”€> Serveur      â”‚
â”‚          Client <â”€â”€200 OK (vide)â”€â”€â”€â”€â”€â”€ Serveur      â”‚
â”‚                                                     â”‚
â”‚  t=7s    [Nouveau message arrive sur serveur]       â”‚
â”‚                                                     â”‚
â”‚  t=10s   Client â”€â”€GET /api/messagesâ”€â”€> Serveur      â”‚
â”‚          Client <â”€â”€200 OK (1 msg)â”€â”€â”€â”€ Serveur       â”‚
â”‚                                                     â”‚
â”‚  Latence de notification : 3 secondes (10s - 7s)    â”‚
â”‚  RequÃªtes inutiles : 2 sur 3 (66%)                  â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ImplÃ©mentation basique

#### JavaScript (Client)

```javascript
/**
 * Polling simple avec setInterval
 */
class SimplePoller {
    constructor(url, interval = 5000) {
        this.url = url;
        this.interval = interval;
        this.intervalId = null;
        this.isRunning = false;
    }

    start() {
        if (this.isRunning) return;

        this.isRunning = true;

        // PremiÃ¨re requÃªte immÃ©diate
        this.poll();

        // Puis requÃªtes pÃ©riodiques
        this.intervalId = setInterval(() => {
            this.poll();
        }, this.interval);
    }

    async poll() {
        try {
            const response = await fetch(this.url);

            if (!response.ok) {
                throw new Error(`HTTP ${response.status}`);
            }

            const data = await response.json();
            this.onData(data);

        } catch (error) {
            console.error('Polling error:', error);
            this.onError(error);
        }
    }

    stop() {
        if (this.intervalId) {
            clearInterval(this.intervalId);
            this.intervalId = null;
        }
        this.isRunning = false;
    }

    // Callbacks Ã  surcharger
    onData(data) {
        console.log('Received data:', data);
    }

    onError(error) {
        console.error('Error:', error);
    }
}

// Utilisation
const poller = new SimplePoller('/api/messages', 5000);

poller.onData = (messages) => {
    messages.forEach(msg => {
        displayMessage(msg);
    });
};

poller.start();

// ArrÃªter quand l'utilisateur quitte la page
window.addEventListener('beforeunload', () => {
    poller.stop();
});
```

#### Python (Serveur Flask)

```python
from flask import Flask, jsonify
from datetime import datetime
import threading

app = Flask(__name__)

# Stockage en mÃ©moire (simplifiÃ©)
messages = []
messages_lock = threading.Lock()

@app.route('/api/messages', methods=['GET'])
def get_messages():
    """
    Endpoint de polling : retourne tous les messages.
    """
    with messages_lock:
        return jsonify({
            'messages': messages,
            'timestamp': datetime.utcnow().isoformat()
        })

@app.route('/api/messages', methods=['POST'])
def post_message():
    """
    Ajouter un nouveau message.
    """
    from flask import request

    message = {
        'id': len(messages) + 1,
        'text': request.json.get('text'),
        'timestamp': datetime.utcnow().isoformat()
    }

    with messages_lock:
        messages.append(message)

    return jsonify(message), 201

if __name__ == '__main__':
    app.run(debug=True, port=5000)
```

### Optimisation : Envoyer seulement les nouveaux messages

**ProblÃ¨me** : Renvoyer tous les messages Ã  chaque requÃªte gaspille de la bande passante.

**Solution** : Le client envoie le timestamp du dernier message reÃ§u.

```javascript
class OptimizedPoller {
    constructor(url, interval = 5000) {
        this.url = url;
        this.interval = interval;
        this.lastTimestamp = null;
        this.intervalId = null;
    }

    start() {
        this.intervalId = setInterval(() => {
            this.poll();
        }, this.interval);

        // PremiÃ¨re requÃªte
        this.poll();
    }

    async poll() {
        // Construire l'URL avec le paramÃ¨tre since
        const url = this.lastTimestamp
            ? `${this.url}?since=${encodeURIComponent(this.lastTimestamp)}`
            : this.url;

        try {
            const response = await fetch(url);
            const data = await response.json();

            if (data.messages.length > 0) {
                this.onData(data.messages);

                // Mettre Ã  jour le timestamp
                this.lastTimestamp = data.timestamp;
            }

        } catch (error) {
            this.onError(error);
        }
    }

    stop() {
        clearInterval(this.intervalId);
    }

    onData(messages) {
        console.log('New messages:', messages);
    }

    onError(error) {
        console.error('Error:', error);
    }
}
```

```python
from flask import Flask, jsonify, request
from datetime import datetime
from dateutil import parser

@app.route('/api/messages', methods=['GET'])
def get_messages():
    """
    Retourne seulement les messages aprÃ¨s 'since'.
    """
    since_param = request.args.get('since')

    with messages_lock:
        if since_param:
            try:
                since_dt = parser.isoparse(since_param)
                # Filtrer les messages plus rÃ©cents
                new_messages = [
                    msg for msg in messages
                    if parser.isoparse(msg['timestamp']) > since_dt
                ]
            except:
                new_messages = messages
        else:
            new_messages = messages

        return jsonify({
            'messages': new_messages,
            'timestamp': datetime.utcnow().isoformat(),
            'count': len(new_messages)
        })
```

### Adaptive Polling (Polling adaptatif)

**Concept** : Ajuster la frÃ©quence de polling selon l'activitÃ©.

```javascript
class AdaptivePoller {
    constructor(url, minInterval = 5000, maxInterval = 60000) {
        this.url = url;
        this.minInterval = minInterval;
        this.maxInterval = maxInterval;
        this.currentInterval = minInterval;
        this.timeoutId = null;
        this.consecutiveEmptyPolls = 0;
    }

    start() {
        this.poll();
    }

    async poll() {
        try {
            const response = await fetch(this.url);
            const data = await response.json();

            if (data.messages.length > 0) {
                // ActivitÃ© dÃ©tectÃ©e : accÃ©lÃ©rer
                this.consecutiveEmptyPolls = 0;
                this.currentInterval = this.minInterval;
                this.onData(data.messages);
            } else {
                // Pas d'activitÃ© : ralentir progressivement
                this.consecutiveEmptyPolls++;
                this.currentInterval = Math.min(
                    this.currentInterval * 1.5,
                    this.maxInterval
                );
            }

            console.log(`Next poll in ${this.currentInterval}ms`);

        } catch (error) {
            this.onError(error);
            // En cas d'erreur, ralentir
            this.currentInterval = Math.min(
                this.currentInterval * 2,
                this.maxInterval
            );
        }

        // Programmer le prochain poll
        this.timeoutId = setTimeout(() => {
            this.poll();
        }, this.currentInterval);
    }

    stop() {
        if (this.timeoutId) {
            clearTimeout(this.timeoutId);
            this.timeoutId = null;
        }
    }

    onData(messages) {
        console.log('Received:', messages);
    }

    onError(error) {
        console.error('Error:', error);
    }
}

// Utilisation
const poller = new AdaptivePoller('/api/messages', 2000, 30000);

// DÃ©marre Ã  2s, peut aller jusqu'Ã  30s si pas d'activitÃ©
poller.start();
```

**Comportement** :
```
ActivitÃ© Ã©levÃ©e:      2s â†’ 2s â†’ 2s â†’ 2s â†’ 2s
ActivitÃ© dÃ©croissante: 2s â†’ 3s â†’ 4.5s â†’ 6.75s
Inactif:              10s â†’ 15s â†’ 22.5s â†’ 30s (max)
Retour d'activitÃ©:    30s â†’ 2s (immÃ©diatement)
```

---

## Long Polling

### Principe fondamental

Le **long polling** inverse le modÃ¨le : au lieu d'interroger Ã  intervalles rÃ©guliers, le client fait une requÃªte qui **reste ouverte jusqu'Ã  ce qu'une nouvelle donnÃ©e soit disponible** ou qu'un timeout se produise.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             LONG POLLING : Timeline                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  t=0s    Client â”€â”€GET /api/long-pollâ”€â”€> Serveur     â”‚
â”‚          [Connexion reste ouverte...]               â”‚
â”‚                                                     â”‚
â”‚  t=7s    [Nouveau message arrive]                   â”‚
â”‚          Client <â”€â”€200 OK (1 msg)â”€â”€â”€â”€ Serveur       â”‚
â”‚                                                     â”‚
â”‚  t=7.1s  Client â”€â”€GET /api/long-pollâ”€â”€> Serveur     â”‚
â”‚          [Connexion reste ouverte...]               â”‚
â”‚                                                     â”‚
â”‚  t=15s   [Nouveau message arrive]                   â”‚
â”‚          Client <â”€â”€200 OK (1 msg)â”€â”€â”€â”€ Serveur       â”‚
â”‚                                                     â”‚
â”‚  Latence de notification : ~100ms (temps rÃ©seau)    â”‚
â”‚  RequÃªtes inutiles : 0%                             â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ImplÃ©mentation basique

#### JavaScript (Client)

```javascript
/**
 * Long polling client
 */
class LongPoller {
    constructor(url, timeout = 30000) {
        this.url = url;
        this.timeout = timeout;
        this.isRunning = false;
        this.abortController = null;
    }

    start() {
        this.isRunning = true;
        this.poll();
    }

    async poll() {
        if (!this.isRunning) return;

        // CrÃ©er un AbortController pour pouvoir annuler
        this.abortController = new AbortController();

        try {
            const response = await fetch(this.url, {
                signal: this.abortController.signal,
                // Note: fetch n'a pas de timeout natif
                // En production, utiliser une promesse avec timeout
            });

            if (!response.ok) {
                throw new Error(`HTTP ${response.status}`);
            }

            const data = await response.json();

            // Traiter les donnÃ©es
            if (data.messages && data.messages.length > 0) {
                this.onData(data.messages);
            }

            // ImmÃ©diatement recommencer le polling
            if (this.isRunning) {
                this.poll();
            }

        } catch (error) {
            if (error.name === 'AbortError') {
                console.log('Long poll aborted');
            } else {
                console.error('Long poll error:', error);
                this.onError(error);

                // Attendre avant de retry en cas d'erreur
                if (this.isRunning) {
                    setTimeout(() => this.poll(), 5000);
                }
            }
        }
    }

    stop() {
        this.isRunning = false;

        if (this.abortController) {
            this.abortController.abort();
        }
    }

    onData(messages) {
        console.log('Received:', messages);
    }

    onError(error) {
        console.error('Error:', error);
    }
}

// Utilisation
const longPoller = new LongPoller('/api/long-poll');

longPoller.onData = (messages) => {
    messages.forEach(msg => {
        displayMessage(msg);
    });
};

longPoller.start();

// Cleanup
window.addEventListener('beforeunload', () => {
    longPoller.stop();
});
```

#### Python (Serveur avec queue)

```python
from flask import Flask, jsonify
from queue import Queue, Empty
import threading
import time

app = Flask(__name__)

# File d'attente pour les nouveaux messages
message_queues = {}
message_queues_lock = threading.Lock()

@app.route('/api/long-poll', methods=['GET'])
def long_poll():
    """
    Long polling endpoint : attend jusqu'Ã  30s pour un nouveau message.
    """
    from flask import request

    # CrÃ©er une queue unique pour ce client
    client_id = request.remote_addr + str(time.time())
    client_queue = Queue()

    with message_queues_lock:
        message_queues[client_id] = client_queue

    try:
        # Attendre jusqu'Ã  30 secondes
        messages = []
        timeout = 30
        start_time = time.time()

        while time.time() - start_time < timeout:
            try:
                # Attendre un message avec timeout court
                msg = client_queue.get(timeout=1)
                messages.append(msg)

                # Optionnel : retourner immÃ©diatement aprÃ¨s le premier message
                break

            except Empty:
                # VÃ©rifier si la connexion est toujours vivante
                # (dans une vraie app, utiliser des mÃ©canismes plus robustes)
                continue

        return jsonify({
            'messages': messages,
            'timestamp': time.time()
        })

    finally:
        # Nettoyer la queue du client
        with message_queues_lock:
            if client_id in message_queues:
                del message_queues[client_id]

@app.route('/api/messages', methods=['POST'])
def post_message():
    """
    Recevoir un nouveau message et le distribuer Ã  tous les clients en attente.
    """
    from flask import request

    message = {
        'id': int(time.time() * 1000),
        'text': request.json.get('text'),
        'timestamp': time.time()
    }

    # Distribuer Ã  tous les clients en attente
    with message_queues_lock:
        for queue in message_queues.values():
            queue.put(message)

    return jsonify(message), 201

if __name__ == '__main__':
    app.run(debug=True, threaded=True, port=5000)
```

### Long Polling avec Node.js (Approche Ã©vÃ©nementielle)

```javascript
const express = require('express');
const EventEmitter = require('events');

const app = express();
app.use(express.json());

// Ã‰metteur d'Ã©vÃ©nements pour les nouveaux messages
const messageEmitter = new EventEmitter();

// Stocker les messages
const messages = [];

/**
 * Endpoint long polling
 */
app.get('/api/long-poll', (req, res) => {
    const timeout = 30000; // 30 secondes
    let timeoutId;

    // Fonction de cleanup
    const cleanup = () => {
        clearTimeout(timeoutId);
        messageEmitter.removeListener('newMessage', onNewMessage);
    };

    // Listener pour nouveaux messages
    const onNewMessage = (message) => {
        cleanup();
        res.json({
            messages: [message],
            timestamp: Date.now()
        });
    };

    // S'abonner aux nouveaux messages
    messageEmitter.once('newMessage', onNewMessage);

    // Timeout : retourner une rÃ©ponse vide
    timeoutId = setTimeout(() => {
        cleanup();
        res.json({
            messages: [],
            timestamp: Date.now()
        });
    }, timeout);

    // Cleanup si le client se dÃ©connecte
    req.on('close', () => {
        cleanup();
    });
});

/**
 * Poster un nouveau message
 */
app.post('/api/messages', (req, res) => {
    const message = {
        id: Date.now(),
        text: req.body.text,
        timestamp: Date.now()
    };

    messages.push(message);

    // Notifier tous les clients en attente
    messageEmitter.emit('newMessage', message);

    res.status(201).json(message);
});

app.listen(3000, () => {
    console.log('Server running on port 3000');
});
```

### Long Polling avec Go (Canaux)

```go
package main

import (
    "encoding/json"
    "net/http"
    "sync"
    "time"
)

type Message struct {
    ID        int64  `json:"id"`
    Text      string `json:"text"`
    Timestamp int64  `json:"timestamp"`
}

type LongPollServer struct {
    // Canal pour broadcast des messages
    broadcast chan Message

    // Map des clients en attente
    clients map[chan Message]bool
    mu      sync.RWMutex
}

func NewLongPollServer() *LongPollServer {
    s := &LongPollServer{
        broadcast: make(chan Message, 100),
        clients:   make(map[chan Message]bool),
    }

    // Goroutine pour distribuer les messages
    go s.distributeMessages()

    return s
}

func (s *LongPollServer) distributeMessages() {
    for msg := range s.broadcast {
        s.mu.RLock()
        for clientChan := range s.clients {
            select {
            case clientChan <- msg:
                // Message envoyÃ©
            default:
                // Client pas prÃªt, skip
            }
        }
        s.mu.RUnlock()
    }
}

func (s *LongPollServer) handleLongPoll(w http.ResponseWriter, r *http.Request) {
    // CrÃ©er un canal pour ce client
    clientChan := make(chan Message, 1)

    // Enregistrer le client
    s.mu.Lock()
    s.clients[clientChan] = true
    s.mu.Unlock()

    // Cleanup Ã  la fin
    defer func() {
        s.mu.Lock()
        delete(s.clients, clientChan)
        close(clientChan)
        s.mu.Unlock()
    }()

    // Attendre un message ou timeout
    timeout := time.After(30 * time.Second)

    select {
    case msg := <-clientChan:
        // Message reÃ§u
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(map[string]interface{}{
            "messages":  []Message{msg},
            "timestamp": time.Now().Unix(),
        })

    case <-timeout:
        // Timeout : retourner rÃ©ponse vide
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(map[string]interface{}{
            "messages":  []Message{},
            "timestamp": time.Now().Unix(),
        })

    case <-r.Context().Done():
        // Client dÃ©connectÃ©
        return
    }
}

func (s *LongPollServer) handlePostMessage(w http.ResponseWriter, r *http.Request) {
    var payload struct {
        Text string `json:"text"`
    }

    if err := json.NewDecoder(r.Body).Decode(&payload); err != nil {
        http.Error(w, "Invalid JSON", http.StatusBadRequest)
        return
    }

    msg := Message{
        ID:        time.Now().UnixNano(),
        Text:      payload.Text,
        Timestamp: time.Now().Unix(),
    }

    // Broadcast aux clients
    select {
    case s.broadcast <- msg:
    default:
        // Canal plein, skip
    }

    w.Header().Set("Content-Type", "application/json")
    w.WriteStatus(201)
    json.NewEncoder(w).Encode(msg)
}

func main() {
    server := NewLongPollServer()

    http.HandleFunc("/api/long-poll", server.handleLongPoll)
    http.HandleFunc("/api/messages", server.handlePostMessage)

    http.ListenAndServe(":8080", nil)
}
```

---

## Comparaison dÃ©taillÃ©e : Short vs Long Polling

### MÃ©triques de performance

```python
"""
Benchmark : Comparer short polling vs long polling
ScÃ©nario : 1 message toutes les 30 secondes pendant 5 minutes
"""

def calculate_metrics(technique, messages_per_period, period_seconds, duration_minutes):
    duration_seconds = duration_minutes * 60
    total_messages = (duration_seconds / period_seconds) * messages_per_period

    if technique == 'short_polling':
        # Polling toutes les 5 secondes
        polling_interval = 5
        total_requests = duration_seconds / polling_interval

        # Overhead : headers HTTP (~500 bytes par requÃªte)
        overhead_per_request = 500
        total_overhead = total_requests * overhead_per_request

        # Latence moyenne : intervalle/2
        avg_latency = polling_interval / 2

        # RequÃªtes inutiles
        useful_requests = total_messages
        wasted_requests = total_requests - useful_requests
        waste_percentage = (wasted_requests / total_requests) * 100

    elif technique == 'long_polling':
        # Une requÃªte par message + reconnexions pÃ©riodiques
        total_requests = total_messages + (duration_seconds / 60)  # Reconnexion toutes les 60s

        # Overhead initial seulement
        overhead_per_request = 500
        total_overhead = total_requests * overhead_per_request

        # Latence moyenne : temps rÃ©seau (~100ms)
        avg_latency = 0.1

        # Presque pas de requÃªtes inutiles
        useful_requests = total_messages
        wasted_requests = total_requests - useful_requests
        waste_percentage = (wasted_requests / total_requests) * 100

    return {
        'total_requests': int(total_requests),
        'total_overhead_kb': total_overhead / 1024,
        'avg_latency_seconds': avg_latency,
        'waste_percentage': waste_percentage
    }

# ScÃ©nario : 1 message/30s pendant 5 minutes
short = calculate_metrics('short_polling', 1, 30, 5)
long = calculate_metrics('long_polling', 1, 30, 5)

print("SHORT POLLING:")
print(f"  Total requests: {short['total_requests']}")
print(f"  Overhead: {short['total_overhead_kb']:.2f} KB")
print(f"  Avg latency: {short['avg_latency_seconds']}s")
print(f"  Waste: {short['waste_percentage']:.1f}%")

print("\nLONG POLLING:")
print(f"  Total requests: {long['total_requests']}")
print(f"  Overhead: {long['total_overhead_kb']:.2f} KB")
print(f"  Avg latency: {long['avg_latency_seconds']}s")
print(f"  Waste: {long['waste_percentage']:.1f}%")

"""
RÃ©sultats typiques:

SHORT POLLING:
  Total requests: 60
  Overhead: 29.30 KB
  Avg latency: 2.5s
  Waste: 83.3%

LONG POLLING:
  Total requests: 15
  Overhead: 7.32 KB
  Avg latency: 0.1s
  Waste: 33.3%

AmÃ©lioration:
  - 75% moins de requÃªtes
  - 75% moins d'overhead
  - 96% moins de latence
"""
```

### Tableau comparatif

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CritÃ¨re              â”‚ Short Polling â”‚ Long Polling      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Latence              â”‚  Moyenne-Hauteâ”‚  Basse            â”‚
â”‚                       â”‚  (intervalle/2)â”‚  (~100ms)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Overhead rÃ©seau      â”‚  TrÃ¨s Ã©levÃ©   â”‚  Faible           â”‚
â”‚                       â”‚  (n req/min)  â”‚  (1 req/Ã©vÃ©nement)â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Charge serveur       â”‚  Constante    â”‚  Variable         â”‚
â”‚                       â”‚  Ã©levÃ©e       â”‚  (par Ã©vÃ©nement)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ScalabilitÃ©          â”‚  Faible       â”‚  Moyenne          â”‚
â”‚                       â”‚  (CPU gaspillÃ©)â”‚  (connexions)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ComplexitÃ© serveur   â”‚  TrÃ¨s simple  â”‚  Moyenne          â”‚
â”‚                       â”‚  (stateless)  â”‚  (gestion queues) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ComplexitÃ© client    â”‚  Triviale     â”‚  Simple           â”‚
â”‚                       â”‚  (setInterval)â”‚  (rÃ©cursion)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CompatibilitÃ© proxy  â”‚  Parfaite     â”‚  Moyenne          â”‚
â”‚                       â”‚               â”‚  (timeouts)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Gaspillage bande     â”‚  Ã‰levÃ©        â”‚  Faible           â”‚
â”‚  passante             â”‚  (66-99%)     â”‚  (10-30%)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Limitations et problÃ¨mes

### 1. ProblÃ¨mes de scalabilitÃ©

**Short Polling : Explosion des requÃªtes**

```
ScÃ©nario : Application de chat avec 10 000 utilisateurs
Polling interval : 5 secondes

Calcul :
- RequÃªtes/seconde = 10 000 / 5 = 2 000 req/s
- RequÃªtes/heure = 2 000 Ã— 3600 = 7 200 000 req/h
- Si 1% sont utiles = 7 128 000 requÃªtes gaspillÃ©es/heure

Impact serveur :
- CPU : traiter 2000 requÃªtes/s
- Bande passante : ~1 MB/s juste en headers
- CoÃ»t cloud : proportionnel aux requÃªtes
```

**Long Polling : ProblÃ¨me de connexions simultanÃ©es**

```
ScÃ©nario : 10 000 utilisateurs connectÃ©s
Chaque utilisateur = 1 connexion ouverte

Impact serveur :
- 10 000 connexions TCP simultanÃ©es
- ~10 MB RAM (1 KB par connexion)
- Limite OS : souvent 65 536 file descriptors
- Load balancer : nÃ©cessite sticky sessions
```

**Solution** : Limiter le nombre de connexions par serveur.

```javascript
// Serveur : limiter les connexions simultanÃ©es
const maxConnections = 5000;
let currentConnections = 0;

app.get('/api/long-poll', (req, res) => {
    if (currentConnections >= maxConnections) {
        return res.status(503).json({
            error: 'Server at capacity, try again later'
        });
    }

    currentConnections++;

    res.on('close', () => {
        currentConnections--;
    });

    // ... reste du code long polling
});

// Monitoring
setInterval(() => {
    console.log(`Active connections: ${currentConnections}/${maxConnections}`);
}, 10000);
```

### 2. Timeouts et proxies

**ProblÃ¨me** : Les proxies/load balancers peuvent timeout les connexions long-lived.

```
Client â”€â”€long pollâ”€â”€> Proxy â”€â”€long pollâ”€â”€> Serveur
                       â”‚
                   [Timeout 60s]
                       â”‚
                       âœ— 504 Gateway Timeout
```

**Solution** : Heartbeat et reconnexion.

```javascript
class ResilientLongPoller {
    constructor(url, maxTimeout = 25000) {  // 25s < timeout proxy (30s)
        this.url = url;
        this.maxTimeout = maxTimeout;
        this.isRunning = false;
    }

    start() {
        this.isRunning = true;
        this.poll();
    }

    async poll() {
        if (!this.isRunning) return;

        const startTime = Date.now();

        try {
            const response = await this.fetchWithTimeout(
                this.url,
                this.maxTimeout
            );

            const data = await response.json();

            if (data.messages && data.messages.length > 0) {
                this.onData(data.messages);
            }

            // VÃ©rifier le temps de rÃ©ponse
            const elapsed = Date.now() - startTime;

            if (elapsed < 1000) {
                // RÃ©ponse immÃ©diate : potentiel problÃ¨me serveur
                console.warn('Server responded too quickly, backing off');
                await this.sleep(2000);
            }

        } catch (error) {
            if (error.name === 'TimeoutError') {
                console.log('Long poll timeout, reconnecting');
                // C'est normal, reconnecter immÃ©diatement
            } else {
                console.error('Long poll error:', error);
                this.onError(error);
                // Attendre avant de retry
                await this.sleep(5000);
            }
        }

        // Reconnecter
        if (this.isRunning) {
            this.poll();
        }
    }

    async fetchWithTimeout(url, timeout) {
        const controller = new AbortController();
        const id = setTimeout(() => controller.abort(), timeout);

        try {
            const response = await fetch(url, {
                signal: controller.signal
            });
            clearTimeout(id);
            return response;
        } catch (error) {
            clearTimeout(id);
            if (error.name === 'AbortError') {
                const timeoutError = new Error('Request timeout');
                timeoutError.name = 'TimeoutError';
                throw timeoutError;
            }
            throw error;
        }
    }

    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }

    stop() {
        this.isRunning = false;
    }

    onData(messages) {
        console.log('Received:', messages);
    }

    onError(error) {
        console.error('Error:', error);
    }
}
```

### 3. Gestion de la concurrence

**ProblÃ¨me** : Plusieurs onglets du mÃªme utilisateur crÃ©ent plusieurs connexions.

```javascript
/**
 * Utiliser SharedWorker pour partager une connexion entre onglets
 */

// shared-worker.js
let longPollConnection = null;
const ports = [];

self.addEventListener('connect', (event) => {
    const port = event.ports[0];
    ports.push(port);

    port.addEventListener('message', (e) => {
        if (e.data.type === 'start' && !longPollConnection) {
            startLongPolling();
        }
    });

    port.start();
});

async function startLongPolling() {
    while (ports.length > 0) {
        try {
            const response = await fetch('/api/long-poll');
            const data = await response.json();

            // Broadcast aux onglets connectÃ©s
            ports.forEach(port => {
                port.postMessage({
                    type: 'data',
                    messages: data.messages
                });
            });

        } catch (error) {
            console.error('Long poll error:', error);
            await new Promise(resolve => setTimeout(resolve, 5000));
        }
    }
}

// Page principale
const worker = new SharedWorker('shared-worker.js');

worker.port.addEventListener('message', (e) => {
    if (e.data.type === 'data') {
        handleMessages(e.data.messages);
    }
});

worker.port.start();
worker.port.postMessage({ type: 'start' });
```

### 4. Battery drain sur mobile

**ProblÃ¨me** : Le polling constant vide la batterie des smartphones.

**Solution** : VisibilitÃ© de la page.

```javascript
class BatteryFriendlyPoller {
    constructor(url) {
        this.url = url;
        this.isVisible = !document.hidden;
        this.poller = null;

        // Ã‰couter les changements de visibilitÃ©
        document.addEventListener('visibilitychange', () => {
            this.isVisible = !document.hidden;

            if (this.isVisible) {
                console.log('Page visible, resuming polling');
                this.start();
            } else {
                console.log('Page hidden, pausing polling');
                this.stop();
            }
        });
    }

    start() {
        if (!this.isVisible || this.poller) return;

        this.poller = new LongPoller(this.url);
        this.poller.onData = this.onData.bind(this);
        this.poller.start();
    }

    stop() {
        if (this.poller) {
            this.poller.stop();
            this.poller = null;
        }
    }

    onData(messages) {
        // Si page pas visible, afficher notification
        if (!this.isVisible && 'Notification' in window) {
            new Notification('Nouveau message', {
                body: messages[0].text,
                icon: '/icon.png'
            });
        } else {
            // Afficher dans l'interface
            displayMessages(messages);
        }
    }
}
```

---

## Patterns avancÃ©s

### 1. Hybrid Polling (Combinaison short + long)

**Concept** : Utiliser long-polling comme principal, short-polling comme backup.

```javascript
class HybridPoller {
    constructor(url) {
        this.url = url;
        this.preferredMethod = 'long'; // ou 'short'
        this.longPoller = null;
        this.shortPollerInterval = null;
        this.consecutiveErrors = 0;
    }

    start() {
        this.startLongPolling();
    }

    startLongPolling() {
        this.longPoller = new LongPoller(this.url);

        this.longPoller.onData = (messages) => {
            this.consecutiveErrors = 0;
            this.onData(messages);
        };

        this.longPoller.onError = (error) => {
            this.consecutiveErrors++;

            // AprÃ¨s 3 erreurs consÃ©cutives, fallback vers short polling
            if (this.consecutiveErrors >= 3) {
                console.log('Long polling failing, switching to short polling');
                this.switchToShortPolling();
            }
        };

        this.longPoller.start();
    }

    switchToShortPolling() {
        // ArrÃªter long polling
        if (this.longPoller) {
            this.longPoller.stop();
            this.longPoller = null;
        }

        // DÃ©marrer short polling
        this.shortPollerInterval = setInterval(async () => {
            try {
                const response = await fetch(this.url);
                const data = await response.json();

                if (data.messages.length > 0) {
                    this.onData(data.messages);
                }

                // Tenter de revenir au long polling aprÃ¨s succÃ¨s
                this.consecutiveErrors = 0;
                if (Math.random() < 0.1) {  // 10% de chance
                    this.tryLongPolling();
                }

            } catch (error) {
                console.error('Short polling error:', error);
            }
        }, 5000);
    }

    tryLongPolling() {
        console.log('Attempting to restore long polling');
        clearInterval(this.shortPollerInterval);
        this.startLongPolling();
    }

    stop() {
        if (this.longPoller) {
            this.longPoller.stop();
        }
        if (this.shortPollerInterval) {
            clearInterval(this.shortPollerInterval);
        }
    }

    onData(messages) {
        console.log('Received:', messages);
    }
}
```

### 2. Exponential Backoff sur erreurs

```javascript
class BackoffPoller {
    constructor(url) {
        this.url = url;
        this.baseDelay = 1000;  // 1 seconde
        this.maxDelay = 60000;  // 1 minute
        this.currentDelay = this.baseDelay;
        this.isRunning = false;
    }

    start() {
        this.isRunning = true;
        this.poll();
    }

    async poll() {
        if (!this.isRunning) return;

        try {
            const response = await fetch(this.url);

            if (!response.ok) {
                throw new Error(`HTTP ${response.status}`);
            }

            const data = await response.json();

            // SuccÃ¨s : reset le delay
            this.currentDelay = this.baseDelay;
            this.onData(data.messages);

            // Continuer immÃ©diatement
            this.poll();

        } catch (error) {
            console.error('Poll error:', error);
            this.onError(error);

            // Augmenter le delay exponentiellement
            console.log(`Retrying in ${this.currentDelay}ms`);

            setTimeout(() => {
                this.poll();
            }, this.currentDelay);

            // Doubler le delay pour la prochaine fois
            this.currentDelay = Math.min(
                this.currentDelay * 2,
                this.maxDelay
            );
        }
    }

    stop() {
        this.isRunning = false;
    }

    onData(messages) {
        console.log('Received:', messages);
    }

    onError(error) {
        console.error('Error:', error);
    }
}
```

### 3. Batching (Regroupement de messages)

**CÃ´tÃ© serveur : Envoyer plusieurs messages groupÃ©s**

```python
from flask import Flask, jsonify
from queue import Queue
import time
import threading

app = Flask(__name__)

class MessageBatcher:
    """
    Regroupe les messages et les envoie par batch.
    """
    def __init__(self, max_batch_size=10, max_wait_seconds=5):
        self.max_batch_size = max_batch_size
        self.max_wait_seconds = max_wait_seconds
        self.pending_messages = []
        self.waiting_clients = []
        self.lock = threading.Lock()

    def add_message(self, message):
        """Ajoute un message et notifie si batch complet."""
        with self.lock:
            self.pending_messages.append(message)

            # Si batch complet, envoyer immÃ©diatement
            if len(self.pending_messages) >= self.max_batch_size:
                self.flush()

    def wait_for_messages(self, client_queue, timeout):
        """Attend des messages ou timeout."""
        with self.lock:
            # Si dÃ©jÃ  des messages, retourner immÃ©diatement
            if self.pending_messages:
                messages = self.pending_messages[:]
                self.pending_messages = []
                return messages

            # Sinon, ajouter le client Ã  la liste d'attente
            self.waiting_clients.append(client_queue)

        # Attendre un message
        try:
            return client_queue.get(timeout=timeout)
        except:
            return []

    def flush(self):
        """Envoie le batch Ã  tous les clients en attente."""
        if not self.pending_messages:
            return

        batch = self.pending_messages[:]
        self.pending_messages = []

        # Envoyer Ã  tous les clients
        for client_queue in self.waiting_clients:
            try:
                client_queue.put(batch, block=False)
            except:
                pass

        self.waiting_clients = []

batcher = MessageBatcher()

@app.route('/api/long-poll', methods=['GET'])
def long_poll():
    client_queue = Queue()
    messages = batcher.wait_for_messages(client_queue, timeout=30)

    return jsonify({
        'messages': messages,
        'count': len(messages)
    })

@app.route('/api/messages', methods=['POST'])
def post_message():
    from flask import request

    message = {
        'id': int(time.time() * 1000),
        'text': request.json.get('text'),
        'timestamp': time.time()
    }

    batcher.add_message(message)

    return jsonify(message), 201

# Flush pÃ©riodique
def periodic_flush():
    while True:
        time.sleep(5)
        with batcher.lock:
            batcher.flush()

threading.Thread(target=periodic_flush, daemon=True).start()

if __name__ == '__main__':
    app.run(debug=True, threaded=True)
```

---

## Cas d'usage rÃ©els

### 1. Facebook Notifications (Historique)

**Avant 2010** : Facebook utilisait le long-polling pour les notifications.

```javascript
// SimplifiÃ© : stratÃ©gie Facebook
class FacebookStylePoller {
    constructor() {
        this.channelUrl = '/api/channel';
        this.isRunning = false;
    }

    async start() {
        this.isRunning = true;

        while (this.isRunning) {
            try {
                // Long poll avec timeout 60s
                const response = await fetch(this.channelUrl + '?timeout=60');
                const data = await response.json();

                // Traiter les Ã©vÃ©nements
                data.events.forEach(event => {
                    switch (event.type) {
                        case 'notification':
                            this.showNotification(event.data);
                            break;
                        case 'message':
                            this.showMessage(event.data);
                            break;
                        case 'presence':
                            this.updatePresence(event.data);
                            break;
                    }
                });

            } catch (error) {
                console.error('Channel error:', error);
                // Backoff exponentiel
                await this.sleep(Math.min(30000, this.errorCount * 1000));
                this.errorCount++;
            }
        }
    }

    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }
}
```

**Migration** : Aujourd'hui, Facebook utilise principalement WebSocket avec fallback vers long-polling.

### 2. Gmail : DÃ©tection de nouveaux emails

**Short polling adaptatif** :

```javascript
// Gmail vÃ©rifie les nouveaux emails
class GmailStylePoller {
    constructor() {
        this.inboxUrl = '/api/inbox';
        this.intervals = {
            active: 2000,    // 2s si utilisateur actif
            inactive: 30000, // 30s si inactif
            background: 60000 // 1min si onglet en arriÃ¨re-plan
        };
        this.currentInterval = this.intervals.active;
        this.lastActivity = Date.now();
        this.intervalId = null;
    }

    start() {
        // DÃ©tecter l'activitÃ© utilisateur
        ['mousedown', 'keydown', 'touchstart'].forEach(event => {
            document.addEventListener(event, () => {
                this.lastActivity = Date.now();
                this.updateInterval();
            });
        });

        // DÃ©tecter visibilitÃ©
        document.addEventListener('visibilitychange', () => {
            this.updateInterval();
        });

        // Commencer le polling
        this.poll();
        this.scheduleNext();
    }

    updateInterval() {
        const timeSinceActivity = Date.now() - this.lastActivity;

        let newInterval;
        if (document.hidden) {
            newInterval = this.intervals.background;
        } else if (timeSinceActivity < 30000) {  // Actif < 30s
            newInterval = this.intervals.active;
        } else {
            newInterval = this.intervals.inactive;
        }

        if (newInterval !== this.currentInterval) {
            this.currentInterval = newInterval;
            this.reschedule();
        }
    }

    async poll() {
        try {
            const response = await fetch(this.inboxUrl);
            const data = await response.json();

            if (data.unread > 0) {
                this.updateUnreadCount(data.unread);
                this.showNotification(`${data.unread} nouveau(x) message(s)`);
            }

        } catch (error) {
            console.error('Inbox poll error:', error);
        }
    }

    scheduleNext() {
        this.intervalId = setTimeout(() => {
            this.poll();
            this.scheduleNext();
        }, this.currentInterval);
    }

    reschedule() {
        clearTimeout(this.intervalId);
        this.scheduleNext();
    }
}
```

### 3. Slack : Messages temps rÃ©el (Legacy)

**Long-polling avec Real-Time Messaging API** :

```python
# Serveur Slack-style (simplifiÃ©)
import time
from collections import defaultdict
import threading

class SlackStyleLongPoll:
    def __init__(self):
        self.channels = defaultdict(list)  # channel_id -> messages
        self.waiting_clients = defaultdict(list)  # channel_id -> client queues
        self.lock = threading.Lock()

    def post_message(self, channel_id, user, text):
        """Poster un message dans un canal."""
        message = {
            'ts': time.time(),
            'user': user,
            'text': text,
            'channel': channel_id
        }

        with self.lock:
            # Ajouter aux messages du canal
            self.channels[channel_id].append(message)

            # Notifier tous les clients en attente sur ce canal
            for client_queue in self.waiting_clients[channel_id]:
                try:
                    client_queue.put(message)
                except:
                    pass

            # Nettoyer
            self.waiting_clients[channel_id] = []

        return message

    def rtm_start(self, user_id, channels):
        """
        DÃ©marrer une session RTM (Real-Time Messaging).
        Retourne l'URL du long-polling endpoint.
        """
        session_id = f"rtm-{user_id}-{int(time.time() * 1000)}"

        return {
            'ok': True,
            'url': f'/rtm/{session_id}',
            'channels': channels
        }

    def rtm_poll(self, session_id, client_queue):
        """
        Long poll pour Ã©vÃ©nements RTM.
        """
        # Attendre des Ã©vÃ©nements (30s max)
        try:
            event = client_queue.get(timeout=30)
            return {
                'ok': True,
                'events': [event]
            }
        except:
            # Timeout : heartbeat
            return {
                'ok': True,
                'events': [],
                'type': 'hello'
            }
```

### 4. Trading platforms : Prix en temps rÃ©el

**Combinaison de techniques** :

```javascript
// Platform de trading : optimisations multiples
class TradingPoller {
    constructor(symbols) {
        this.symbols = symbols;
        this.prices = {};

        // Polling diffÃ©renciÃ© par volatilitÃ©
        this.pollingIntervals = {
            'BTC': 1000,   // Bitcoin : 1s (trÃ¨s volatile)
            'ETH': 2000,   // Ethereum : 2s
            'AAPL': 5000,  // Actions : 5s
            'BONDS': 30000 // Obligations : 30s (stable)
        };
    }

    start() {
        this.symbols.forEach(symbol => {
            const interval = this.pollingIntervals[symbol] || 5000;
            this.startPolling(symbol, interval);
        });
    }

    startPolling(symbol, interval) {
        const poll = async () => {
            try {
                const response = await fetch(`/api/price/${symbol}`);
                const data = await response.json();

                // DÃ©tecter changement significatif
                const oldPrice = this.prices[symbol];
                const newPrice = data.price;

                if (oldPrice) {
                    const changePct = Math.abs((newPrice - oldPrice) / oldPrice);

                    // Si changement > 1%, accÃ©lÃ©rer temporairement
                    if (changePct > 0.01) {
                        console.log(`${symbol} moved ${changePct * 100}%, accelerating polling`);

                        // Polling rapide pendant 30s
                        const fastInterval = interval / 2;
                        const fastPolls = Math.floor(30000 / fastInterval);

                        for (let i = 0; i < fastPolls; i++) {
                            await this.sleep(fastInterval);
                            await poll();
                        }
                    }
                }

                this.prices[symbol] = newPrice;
                this.updateUI(symbol, data);

            } catch (error) {
                console.error(`Error polling ${symbol}:`, error);
            }
        };

        // PremiÃ¨re requÃªte
        poll();

        // Puis pÃ©riodique
        setInterval(poll, interval);
    }

    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }

    updateUI(symbol, data) {
        // Mettre Ã  jour l'interface
        document.querySelector(`#price-${symbol}`).textContent = data.price;
    }
}
```

---

## Migration vers des solutions modernes

### Checklist de migration

```javascript
/**
 * StratÃ©gie de migration progressive
 * Polling â†’ SSE ou WebSocket
 */

class ProgressiveMigration {
    constructor(config) {
        this.fallbackChain = [
            { name: 'WebSocket', test: this.testWebSocket, impl: this.useWebSocket },
            { name: 'SSE', test: this.testSSE, impl: this.useSSE },
            { name: 'Long-Polling', test: () => true, impl: this.useLongPolling }
        ];

        this.activeMethod = null;
    }

    async initialize() {
        // Tester chaque mÃ©thode dans l'ordre
        for (const method of this.fallbackChain) {
            if (await method.test.call(this)) {
                console.log(`Using ${method.name}`);
                this.activeMethod = method.impl.call(this);
                break;
            }
        }
    }

    testWebSocket() {
        // VÃ©rifier support navigateur
        if (!('WebSocket' in window)) {
            return false;
        }

        // Tester connectivitÃ© (async)
        return new Promise((resolve) => {
            const ws = new WebSocket('wss://example.com/test');

            ws.onopen = () => {
                ws.close();
                resolve(true);
            };

            ws.onerror = () => {
                resolve(false);
            };

            setTimeout(() => resolve(false), 5000);
        });
    }

    testSSE() {
        return 'EventSource' in window;
    }

    useWebSocket() {
        const ws = new WebSocket('wss://example.com/ws');

        ws.onmessage = (event) => {
            const data = JSON.parse(event.data);
            this.handleData(data);
        };

        return ws;
    }

    useSSE() {
        const sse = new EventSource('/api/events');

        sse.onmessage = (event) => {
            const data = JSON.parse(event.data);
            this.handleData(data);
        };

        return sse;
    }

    useLongPolling() {
        const poller = new LongPoller('/api/long-poll');

        poller.onData = (messages) => {
            this.handleData(messages);
        };

        poller.start();
        return poller;
    }

    handleData(data) {
        console.log('Received data:', data);
    }
}

// Utilisation
const migration = new ProgressiveMigration();
await migration.initialize();
```

### Feature flags pour dÃ©ploiement progressif

```python
# Serveur : activer progressivement les nouvelles techniques

class FeatureFlags:
    def __init__(self):
        self.flags = {
            'websocket_enabled': 0.1,  # 10% des utilisateurs
            'sse_enabled': 0.3,        # 30% des utilisateurs
            'long_polling_only': 0.6   # 60% des utilisateurs
        }

    def get_method_for_user(self, user_id):
        # Hash stable basÃ© sur user_id
        hash_value = hash(user_id) % 100 / 100.0

        if hash_value < self.flags['websocket_enabled']:
            return 'websocket'
        elif hash_value < self.flags['websocket_enabled'] + self.flags['sse_enabled']:
            return 'sse'
        else:
            return 'long_polling'

flags = FeatureFlags()

@app.route('/api/connection-info')
def connection_info():
    from flask import request
    user_id = request.headers.get('X-User-ID')

    method = flags.get_method_for_user(user_id)

    return jsonify({
        'method': method,
        'urls': {
            'websocket': 'wss://example.com/ws',
            'sse': '/api/events',
            'long_polling': '/api/long-poll'
        }
    })
```

---

## Monitoring et mÃ©triques

### MÃ©triques essentielles

```javascript
class PollingMetrics {
    constructor() {
        this.metrics = {
            totalRequests: 0,
            successfulRequests: 0,
            failedRequests: 0,
            emptyResponses: 0,
            dataResponses: 0,
            totalLatency: 0,
            latencies: []
        };
    }

    recordRequest(success, hasData, latency) {
        this.metrics.totalRequests++;

        if (success) {
            this.metrics.successfulRequests++;

            if (hasData) {
                this.metrics.dataResponses++;
            } else {
                this.metrics.emptyResponses++;
            }
        } else {
            this.metrics.failedRequests++;
        }

        if (latency) {
            this.metrics.totalLatency += latency;
            this.metrics.latencies.push(latency);

            // Garder seulement les 1000 derniÃ¨res
            if (this.metrics.latencies.length > 1000) {
                this.metrics.latencies.shift();
            }
        }
    }

    getStats() {
        const avgLatency = this.metrics.totalLatency / this.metrics.totalRequests;
        const successRate = this.metrics.successfulRequests / this.metrics.totalRequests;
        const wasteRate = this.metrics.emptyResponses / this.metrics.successfulRequests;

        return {
            ...this.metrics,
            avgLatency,
            successRate,
            wasteRate,
            p95Latency: this.percentile(0.95),
            p99Latency: this.percentile(0.99)
        };
    }

    percentile(p) {
        const sorted = [...this.metrics.latencies].sort((a, b) => a - b);
        const index = Math.ceil(sorted.length * p) - 1;
        return sorted[index] || 0;
    }
}

// IntÃ©gration
const metrics = new PollingMetrics();

async function monitoredPoll() {
    const start = Date.now();

    try {
        const response = await fetch('/api/poll');
        const data = await response.json();
        const latency = Date.now() - start;

        metrics.recordRequest(
            true,
            data.messages.length > 0,
            latency
        );

        return data;

    } catch (error) {
        const latency = Date.now() - start;
        metrics.recordRequest(false, false, latency);
        throw error;
    }
}

// Reporting pÃ©riodique
setInterval(() => {
    const stats = metrics.getStats();
    console.log('Polling stats:', stats);

    // Envoyer Ã  analytics
    sendToAnalytics(stats);
}, 60000);
```

---

## Checklist pour production

- [ ] **Intervalles optimisÃ©s** selon frÃ©quence rÃ©elle de mise Ã  jour
- [ ] **Adaptive polling** implÃ©mentÃ© si charge variable
- [ ] **Timeouts configurÃ©s** (short polling: 5-10s, long polling: 25-30s)
- [ ] **Retry avec backoff** en cas d'erreur
- [ ] **Gestion visibilitÃ© page** (pause si hidden)
- [ ] **Limitation connexions** cÃ´tÃ© serveur (long polling)
- [ ] **Batching** si plusieurs messages simultanÃ©s
- [ ] **MÃ©triques exposÃ©es** (latence, taux d'erreur, waste rate)
- [ ] **Alertes configurÃ©es** (latence Ã©levÃ©e, taux d'Ã©chec)
- [ ] **Plan de migration** vers SSE/WebSocket dÃ©fini
- [ ] **Feature flags** pour rollout progressif
- [ ] **Tests de charge** validant comportement sous charge
- [ ] **Documentation** pour l'Ã©quipe

---

## Conclusion

Le polling et long-polling sont des techniques **simples mais limitÃ©es** pour la communication temps rÃ©el. Bien qu'elles aient Ã©tÃ© largement utilisÃ©es par le passÃ© (et le sont encore dans certains contextes), elles prÃ©sentent des limitations importantes :

**Short Polling** :
- âœ… Ultra-simple, compatible partout
- âŒ Latence Ã©levÃ©e, gaspillage rÃ©seau massif
- **Verdict** : Utiliser seulement pour donnÃ©es changeant rarement (> 30s)

**Long Polling** :
- âœ… Latence faible, pas de gaspillage
- âœ… Compatible avec HTTP standard
- âŒ ComplexitÃ© serveur, problÃ¨mes de scalabilitÃ©
- **Verdict** : Bon compromis pour fallback, pas optimal comme solution principale

**Recommandations** :
1. **Nouvelles applications** : Utiliser SSE (unidirectionnel) ou WebSocket (bidirectionnel)
2. **Applications existantes** : Migrer progressivement avec feature flags
3. **Fallback** : Garder long-polling comme backup pour compatibilitÃ©

Les sections suivantes exploreront **SSE et WebSocket**, les solutions modernes qui ont largement remplacÃ© le polling pour la plupart des use cases temps rÃ©el.

---


â­ï¸ [Server-Sent Events (SSE) : streaming unidirectionnel](/08-programmation-reseau/09.2-server-sent-events.md)
