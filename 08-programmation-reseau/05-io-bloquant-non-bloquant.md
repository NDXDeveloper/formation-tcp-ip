üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.5 I/O bloquant vs non-bloquant

## Introduction

Le choix entre **I/O bloquant** et **I/O non-bloquant** est l'une des d√©cisions architecturales les plus importantes en programmation r√©seau. Ce choix d√©termine :

- **Combien de connexions** votre application peut g√©rer
- **Comment** votre code est structur√©
- **La complexit√©** de votre application
- **Les performances** sous charge

Comprendre ces mod√®les est essentiel pour construire des applications r√©seau scalables et performantes.

## Qu'est-ce que le blocage (Blocking) ?

### D√©finition

Une op√©ration est **bloquante** quand elle **suspend l'ex√©cution du thread** jusqu'√† ce qu'elle soit compl√®te ou qu'un timeout survienne.

```python
import socket

# Op√©ration BLOQUANTE
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.connect(('example.com', 80))  # Thread bloqu√© ici

# Le code ci-dessous ne s'ex√©cute PAS tant que connect() n'est pas termin√©
print("Connect√©!")  # Cette ligne attend
```

### Visualisation du blocage

```
Thread d'ex√©cution :

t=0ms    | Code avant connect()
t=1ms    | sock.connect() commence
         |
         | ‚è∏Ô∏è  THREAD BLOQU√â
         | (attend handshake TCP)
         |
t=50ms   | Connexion √©tablie, connect() retourne
t=51ms   | Code apr√®s connect()
```

**Pendant le blocage** :
- Le thread ne fait **rien** (consomme un slot de thread)
- Le CPU est **inutilis√©** par ce thread
- Aucun autre code ne peut s'ex√©cuter dans ce thread

## I/O Bloquant en d√©tail

### Op√©rations bloquantes courantes

```python
import socket

sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

# 1. connect() - Bloque pendant le 3-way handshake
sock.connect(('example.com', 80))  # 10-100ms typique

# 2. send() - Peut bloquer si le buffer d'envoi est plein
sock.send(b"x" * 1000000)  # Bloque si le buffer est satur√©

# 3. recv() - Bloque jusqu'√† r√©ception de donn√©es
data = sock.recv(4096)  # Bloque ind√©finiment par d√©faut

# 4. accept() - Bloque jusqu'√† connexion entrante
server.listen(5)
client, addr = server.accept()  # Bloque jusqu'√† un client
```

### Exemple : Serveur bloquant simple

```python
import socket

def blocking_echo_server():
    """Serveur echo bloquant (mono-client)"""
    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server.bind(('0.0.0.0', 8080))
    server.listen(5)

    print("Serveur en √©coute sur :8080")

    while True:
        # 1. Bloque jusqu'√† connexion entrante
        print("En attente d'un client...")
        client_sock, client_addr = server.accept()
        print(f"Client connect√©: {client_addr}")

        # 2. Traite CE client uniquement
        while True:
            # 3. Bloque jusqu'√† r√©ception de donn√©es
            data = client_sock.recv(1024)

            if not data:
                break

            print(f"Re√ßu: {data}")

            # 4. Envoie la r√©ponse (peut bloquer)
            client_sock.send(b"Echo: " + data)

        client_sock.close()
        print(f"Client {client_addr} d√©connect√©")

# PROBL√àME : Un seul client √† la fois !
# Si Client A est connect√©, Client B attend ind√©finiment
```

**Test du probl√®me** :

```bash
# Terminal 1 : Serveur
python blocking_server.py

# Terminal 2 : Client A se connecte
telnet localhost 8080
# Fonctionne

# Terminal 3 : Client B tente de se connecter
telnet localhost 8080
# BLOQU√â ! Attend que Client A se d√©connecte
```

### Solution 1 : Thread par connexion

```python
import socket
import threading

def blocking_echo_server_threaded():
    """Serveur echo avec un thread par client"""
    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server.bind(('0.0.0.0', 8080))
    server.listen(5)

    print("Serveur multi-thread en √©coute sur :8080")

    while True:
        client_sock, client_addr = server.accept()
        print(f"Client connect√©: {client_addr}")

        # Cr√©er un thread d√©di√© pour ce client
        client_thread = threading.Thread(
            target=handle_client,
            args=(client_sock, client_addr)
        )
        client_thread.daemon = True
        client_thread.start()

def handle_client(sock, addr):
    """G√®re un client dans son propre thread"""
    try:
        while True:
            data = sock.recv(1024)
            if not data:
                break

            print(f"[{addr}] Re√ßu: {data}")
            sock.send(b"Echo: " + data)

    finally:
        sock.close()
        print(f"Client {addr} d√©connect√©")

# AVANTAGE : Plusieurs clients simultan√©s
# PROBL√àME : Ne scale pas au-del√† de ~1000 threads
```

**Pourquoi √ßa ne scale pas ?**

```
1 thread = ~8 MB de stack (Linux)
1000 threads = ~8 GB de RAM juste pour les stacks
10000 threads = ~80 GB de RAM !

+ Overhead de context switching
+ Contention sur les locks
‚Üí Impossible de g√©rer 10000+ connexions
```

### Le probl√®me C10K

**C10K** = G√©rer **10 000 connexions concurrentes**

```python
# Approche thread-per-connection
10000 clients √ó 8 MB par thread = 80 GB de RAM
+ Context switching entre 10000 threads = CPU satur√©

# R√©sultat : IMPOSSIBLE avec I/O bloquant + threads
```

Historiquement (ann√©es 1990-2000), les serveurs ne pouvaient pas g√©rer plus de quelques milliers de connexions simultan√©es.

**Cas d'usage r√©el** :
- **Chat en ligne** : 100 000 utilisateurs connect√©s
- **Gaming** : 50 000 joueurs sur un serveur
- **Streaming** : 1 million de viewers simultan√©s

‚Üí I/O bloquant inadapt√©

## I/O Non-bloquant en d√©tail

### Principe

Une op√©ration **non-bloquante** retourne **imm√©diatement**, m√™me si l'op√©ration n'est pas compl√®te.

```python
import socket

sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

# Passer en mode non-bloquant
sock.setblocking(False)

try:
    sock.connect(('example.com', 80))
except BlockingIOError:
    # Normal ! connect() retourne imm√©diatement
    # La connexion continue en arri√®re-plan
    print("Connexion en cours...")

# Le code continue IMM√âDIATEMENT
print("Cette ligne s'ex√©cute tout de suite!")
```

### Visualisation du non-bloquant

```
Thread d'ex√©cution :

t=0ms    | Code avant connect()
t=1ms    | sock.connect() lance la connexion
t=1ms    | BlockingIOError lev√©e
t=1ms    | Code apr√®s connect()
         |
         | (Thread continue, connexion en arri√®re-plan)
         |
t=50ms   | Connexion r√©ellement √©tablie (on ne le sait pas encore)
```

### Op√©rations non-bloquantes

```python
import socket
import errno

sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.setblocking(False)

# 1. connect() non-bloquant
try:
    sock.connect(('example.com', 80))
except BlockingIOError as e:
    # errno.EINPROGRESS = connexion en cours
    if e.errno != errno.EINPROGRESS:
        raise

# 2. recv() non-bloquant
try:
    data = sock.recv(1024)
    print(f"Re√ßu: {data}")
except BlockingIOError:
    # Pas de donn√©es disponibles pour le moment
    print("Pas de donn√©es (normal)")

# 3. send() non-bloquant
try:
    sent = sock.send(b"Hello")
    print(f"Envoy√© {sent} octets")
except BlockingIOError:
    # Buffer d'envoi plein, r√©essayer plus tard
    print("Buffer plein (normal)")

# 4. accept() non-bloquant
try:
    client, addr = server.accept()
    print(f"Client: {addr}")
except BlockingIOError:
    # Pas de client en attente (normal)
    print("Pas de client (normal)")
```

### Probl√®me : Polling na√Øf

```python
import socket
import time

def naive_nonblocking_client():
    """Client non-bloquant avec polling na√Øf"""
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.setblocking(False)

    # 1. Lancer la connexion
    try:
        sock.connect(('example.com', 80))
    except BlockingIOError:
        pass  # Normal

    # 2. Attendre que la connexion soit √©tablie (MAUVAIS !)
    while True:
        try:
            # Tenter d'envoyer (teste si connect√©)
            sock.send(b'GET / HTTP/1.1\r\n\r\n')
            print("Connect√©!")
            break
        except OSError:
            # Pas encore connect√©
            print("Pas encore connect√©, retry...")
            time.sleep(0.1)  # GASPILLAGE DE CPU

    # 3. Lire la r√©ponse
    response = b''
    while True:
        try:
            chunk = sock.recv(4096)
            if not chunk:
                break
            response += chunk
        except BlockingIOError:
            # Pas de donn√©es pour le moment
            time.sleep(0.01)  # GASPILLAGE DE CPU
            continue

    print(response.decode())

# PROBL√àME : Boucles actives (busy-waiting) gaspillent le CPU
```

**Pourquoi c'est mauvais ?**

```python
# CPU usage pendant le busy-waiting :
while True:
    try:
        data = sock.recv(1024)
    except BlockingIOError:
        time.sleep(0.001)  # 1ms
        # CPU √† 100% sur ce thread !
```

**Solution** : Multiplexage I/O (section 8.6)

## Comparaison d√©taill√©e

### Tableau comparatif

| Aspect | I/O Bloquant | I/O Non-bloquant |
|--------|--------------|------------------|
| **Thread bloqu√© ?** | ‚úÖ Oui, jusqu'√† compl√©tion | ‚ùå Non, retour imm√©diat |
| **Simplicit√©** | ‚úÖ Code s√©quentiel simple | ‚ùå Plus complexe (√©tat) |
| **Scalabilit√©** | ‚ùå Limit√©e (threads) | ‚úÖ Excellente (event loop) |
| **CPU usage** | ‚úÖ Faible (thread sleep) | ‚ö†Ô∏è √âlev√© (polling na√Øf) |
| **Latence** | ‚ö†Ô∏è Variable (context switch) | ‚úÖ Pr√©visible |
| **D√©bogage** | ‚úÖ Plus facile | ‚ùå Plus difficile |
| **Cas d'usage** | Peu de connexions | Beaucoup de connexions |

### Code comparatif

#### Bloquant

```python
# I/O BLOQUANT : Simple et s√©quentiel
def handle_client_blocking(sock):
    """Gestion bloquante d'un client"""
    # 1. Lire la requ√™te (bloque)
    request = sock.recv(1024)

    # 2. Traiter
    response = process_request(request)

    # 3. Envoyer (bloque)
    sock.sendall(response)

    # 4. Fermer
    sock.close()

# Code SIMPLE, LISIBLE, S√âQUENTIEL
# Mais n√©cessite 1 thread par client
```

#### Non-bloquant

```python
# I/O NON-BLOQUANT : Plus complexe
class ClientHandler:
    """Gestion non-bloquante d'un client (machine √† √©tats)"""

    def __init__(self, sock):
        self.sock = sock
        self.state = 'READING'
        self.buffer_in = b''
        self.buffer_out = b''

    def handle(self):
        """Appel√© r√©p√©titivement par l'event loop"""
        if self.state == 'READING':
            try:
                chunk = self.sock.recv(1024)
                if not chunk:
                    self.state = 'CLOSED'
                    return

                self.buffer_in += chunk

                if b'\r\n\r\n' in self.buffer_in:
                    # Requ√™te compl√®te
                    self.buffer_out = process_request(self.buffer_in)
                    self.state = 'WRITING'

            except BlockingIOError:
                # Pas de donn√©es, on reviendra plus tard
                pass

        elif self.state == 'WRITING':
            try:
                sent = self.sock.send(self.buffer_out)
                self.buffer_out = self.buffer_out[sent:]

                if not self.buffer_out:
                    # Tout envoy√©
                    self.state = 'CLOSED'

            except BlockingIOError:
                # Buffer plein, on reviendra plus tard
                pass

        elif self.state == 'CLOSED':
            self.sock.close()

# Code COMPLEXE (machine √† √©tats)
# Mais un seul thread peut g√©rer TOUS les clients
```

### Performances compar√©es

```python
import socket
import threading
import time

# Benchmark : 1000 requ√™tes HTTP

# 1. I/O Bloquant + Threads
def benchmark_blocking():
    def fetch(url):
        sock = socket.socket()
        sock.connect(('example.com', 80))
        sock.send(b'GET / HTTP/1.1\r\nHost: example.com\r\n\r\n')
        response = sock.recv(4096)
        sock.close()
        return response

    start = time.time()
    threads = []
    for i in range(1000):
        t = threading.Thread(target=fetch, args=('http://example.com',))
        threads.append(t)
        t.start()

    for t in threads:
        t.join()

    duration = time.time() - start
    print(f"Bloquant + Threads: {duration:.2f}s")
    # R√©sultat typique : 15-30s (overhead de threads)

# 2. I/O Non-bloquant + Event Loop (asyncio)
import asyncio

async def benchmark_nonblocking():
    async def fetch(url):
        reader, writer = await asyncio.open_connection('example.com', 80)
        writer.write(b'GET / HTTP/1.1\r\nHost: example.com\r\n\r\n')
        response = await reader.read(4096)
        writer.close()
        return response

    start = time.time()
    tasks = [fetch('http://example.com') for _ in range(1000)]
    await asyncio.gather(*tasks)

    duration = time.time() - start
    print(f"Non-bloquant + asyncio: {duration:.2f}s")
    # R√©sultat typique : 2-5s (pas d'overhead de threads)

# asyncio.run(benchmark_nonblocking())
```

**R√©sultats typiques** :
```
1000 connexions simultan√©es :
- Bloquant + Threads : 20s, 8 GB RAM
- Non-bloquant + Event loop : 3s, 100 MB RAM

10000 connexions :
- Bloquant + Threads : IMPOSSIBLE (out of memory)
- Non-bloquant + Event loop : 25s, 500 MB RAM
```

## Patterns de concurrence

### Pattern 1 : Thread-per-connection (Bloquant)

```python
import socket
import threading

class ThreadedServer:
    """Serveur avec un thread par connexion"""

    def __init__(self, host='0.0.0.0', port=8080):
        self.host = host
        self.port = port
        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

    def start(self):
        self.server.bind((self.host, self.port))
        self.server.listen(100)
        print(f"Serveur thread-per-connection sur {self.host}:{self.port}")

        while True:
            client, addr = self.server.accept()

            # Nouveau thread pour chaque client
            thread = threading.Thread(
                target=self.handle_client,
                args=(client, addr)
            )
            thread.daemon = True
            thread.start()

    def handle_client(self, sock, addr):
        """Thread d√©di√© pour un client"""
        print(f"[Thread {threading.current_thread().name}] Client {addr}")

        try:
            while True:
                data = sock.recv(1024)
                if not data:
                    break
                sock.sendall(b"Echo: " + data)
        finally:
            sock.close()

# AVANTAGES :
# ‚úÖ Code simple et lisible
# ‚úÖ Chaque client isol√© dans son thread
# ‚úÖ Gestion d'erreur simple (exception dans un thread = autres OK)

# INCONV√âNIENTS :
# ‚ùå Limit√© √† ~1000 connexions
# ‚ùå Overhead m√©moire (8 MB/thread)
# ‚ùå Context switching co√ªteux
```

**Cas d'usage appropri√©s** :
- Serveurs avec < 100 connexions simultan√©es
- Applications o√π chaque connexion fait du CPU intensif
- Prototypage rapide

### Pattern 2 : Thread Pool (Bloquant)

```python
import socket
import threading
from queue import Queue

class ThreadPoolServer:
    """Serveur avec pool de threads (nombre fixe)"""

    def __init__(self, host='0.0.0.0', port=8080, num_workers=10):
        self.host = host
        self.port = port
        self.num_workers = num_workers

        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

        # File de clients en attente
        self.client_queue = Queue()

        # Pool de workers
        self.workers = []

    def start(self):
        self.server.bind((self.host, self.port))
        self.server.listen(100)

        # D√©marrer les workers
        for i in range(self.num_workers):
            worker = threading.Thread(target=self.worker_thread, args=(i,))
            worker.daemon = True
            worker.start()
            self.workers.append(worker)

        print(f"Serveur avec {self.num_workers} workers sur {self.host}:{self.port}")

        # Accepter les clients et les mettre en queue
        while True:
            client, addr = self.server.accept()
            print(f"Client {addr} ajout√© √† la queue")
            self.client_queue.put((client, addr))

    def worker_thread(self, worker_id):
        """Worker qui traite les clients de la queue"""
        print(f"Worker {worker_id} d√©marr√©")

        while True:
            # Attendre un client (bloquant sur queue)
            client, addr = self.client_queue.get()

            print(f"[Worker {worker_id}] Traite client {addr}")

            try:
                while True:
                    data = client.recv(1024)
                    if not data:
                        break
                    client.sendall(b"Echo: " + data)
            finally:
                client.close()
                print(f"[Worker {worker_id}] Client {addr} d√©connect√©")
                self.client_queue.task_done()

# AVANTAGES :
# ‚úÖ Nombre de threads contr√¥l√© (pas d'explosion)
# ‚úÖ Meilleure utilisation des ressources
# ‚úÖ Code relativement simple

# INCONV√âNIENTS :
# ‚ùå Si tous les workers bloqu√©s, nouveaux clients attendent
# ‚ùå Toujours limit√© par le nombre de threads
```

**Cas d'usage** :
- Serveurs avec charge variable
- Limitation des ressources (RAM, CPU)
- Traitement de t√¢ches de dur√©e similaire

### Pattern 3 : Event Loop (Non-bloquant)

```python
import socket
import select

class EventLoopServer:
    """Serveur avec event loop (I/O non-bloquant)"""

    def __init__(self, host='0.0.0.0', port=8080):
        self.host = host
        self.port = port

        # Socket serveur
        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.server.setblocking(False)  # Non-bloquant !

        # Toutes les sockets √† surveiller
        self.sockets = []

        # Buffers pour chaque client
        self.buffers = {}

    def start(self):
        self.server.bind((self.host, self.port))
        self.server.listen(100)
        self.sockets.append(self.server)

        print(f"Serveur event-loop sur {self.host}:{self.port}")

        # Event loop principal (SINGLE THREAD !)
        while True:
            # select() bloque jusqu'√† activit√© sur une socket
            readable, writable, exceptional = select.select(
                self.sockets,  # Sockets √† lire
                [],            # Sockets √† √©crire
                self.sockets,  # Sockets en erreur
                1.0            # Timeout 1s
            )

            # Traiter les sockets pr√™tes
            for sock in readable:
                if sock is self.server:
                    # Nouvelle connexion
                    self.accept_client()
                else:
                    # Donn√©es d'un client
                    self.handle_client(sock)

            # Traiter les erreurs
            for sock in exceptional:
                self.close_client(sock)

    def accept_client(self):
        """Accepte un nouveau client"""
        try:
            client, addr = self.server.accept()
            client.setblocking(False)  # Non-bloquant !

            self.sockets.append(client)
            self.buffers[client] = b''

            print(f"Client connect√©: {addr}")

        except BlockingIOError:
            # Pas de client (ne devrait pas arriver)
            pass

    def handle_client(self, sock):
        """G√®re les donn√©es d'un client"""
        try:
            data = sock.recv(1024)

            if not data:
                # Client d√©connect√©
                self.close_client(sock)
                return

            # Echo
            sock.send(b"Echo: " + data)

        except BlockingIOError:
            # Pas de donn√©es (ne devrait pas arriver apr√®s select)
            pass

        except Exception as e:
            print(f"Erreur client: {e}")
            self.close_client(sock)

    def close_client(self, sock):
        """Ferme un client"""
        print(f"Fermeture client")
        self.sockets.remove(sock)
        if sock in self.buffers:
            del self.buffers[sock]
        sock.close()

# AVANTAGES :
# ‚úÖ UN SEUL THREAD pour TOUS les clients
# ‚úÖ Tr√®s scalable (10000+ connexions)
# ‚úÖ Faible consommation m√©moire
# ‚úÖ Pas de context switching

# INCONV√âNIENTS :
# ‚ùå Code plus complexe (machine √† √©tats)
# ‚ùå Une op√©ration bloquante bloque TOUT
# ‚ùå Debugging plus difficile
```

**Cas d'usage** :
- Serveurs haute performance (Nginx, Redis, Node.js)
- Beaucoup de connexions I/O-bound
- Microservices

## Cas d'usage r√©els par industrie

### 1. Serveur Web (Nginx vs Apache)

**Apache (mode prefork - I/O bloquant)** :

```python
# Mod√®le Apache prefork (simplifi√©)
class ApachePrefork:
    """Process par connexion (bloquant)"""

    def __init__(self, num_processes=10):
        self.num_processes = num_processes

    def start(self):
        # Fork plusieurs processus workers
        for i in range(self.num_processes):
            pid = os.fork()
            if pid == 0:  # Child process
                self.worker()
                exit(0)

        # Parent attend
        for i in range(self.num_processes):
            os.wait()

    def worker(self):
        """Worker process (bloquant)"""
        server = socket.socket()
        server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        server.bind(('0.0.0.0', 8080))
        server.listen(100)

        while True:
            client, addr = server.accept()  # Bloque
            self.handle_request(client)
            client.close()

# Limite : ~256 processus = ~256 requ√™tes simultan√©es
```

**Nginx (event-driven - I/O non-bloquant)** :

```python
# Mod√®le Nginx (simplifi√©)
class NginxEventDriven:
    """Event loop par worker (non-bloquant)"""

    def __init__(self, num_workers=4):
        self.num_workers = num_workers

    def start(self):
        # Fork plusieurs workers
        for i in range(self.num_workers):
            pid = os.fork()
            if pid == 0:
                self.event_loop_worker()
                exit(0)

    def event_loop_worker(self):
        """Worker avec event loop (epoll)"""
        # Utilise epoll (Linux) pour 10000+ connexions
        epoll = select.epoll()

        server = socket.socket()
        server.setblocking(False)
        server.bind(('0.0.0.0', 8080))
        server.listen(1024)

        epoll.register(server.fileno(), select.EPOLLIN)

        connections = {}

        while True:
            # Attendre des √©v√©nements
            events = epoll.poll(timeout=1.0)

            for fd, event in events:
                if fd == server.fileno():
                    # Nouvelle connexion
                    client, addr = server.accept()
                    client.setblocking(False)
                    epoll.register(client.fileno(), select.EPOLLIN)
                    connections[client.fileno()] = client

                elif event & select.EPOLLIN:
                    # Donn√©es √† lire
                    # ... traiter sans bloquer

# Capacit√© : 10000+ connexions par worker
# 4 workers = 40000+ connexions simultan√©es
```

**R√©sultats r√©els** :

```
Apache (prefork) :
- 256 connexions simultan√©es max
- 1 GB RAM pour 256 processus
- ~5000 req/sec

Nginx (event-driven) :
- 40000+ connexions simultan√©es
- 200 MB RAM pour 4 workers
- ~50000 req/sec

‚Üí 10x plus de connexions, 5x moins de RAM, 10x plus de d√©bit
```

### 2. Base de donn√©es (Redis)

**Redis** : Architecture single-threaded event-loop

```python
# Mod√®le Redis (tr√®s simplifi√©)
class RedisLikeServer:
    """Serveur cl√©-valeur single-thread (comme Redis)"""

    def __init__(self):
        self.data = {}  # Store cl√©-valeur
        self.sockets = []
        self.buffers = {}

    def event_loop(self):
        """Event loop principal (SINGLE THREAD)"""
        epoll = select.epoll()

        server = socket.socket()
        server.setblocking(False)
        server.bind(('0.0.0.0', 6379))
        server.listen(1000)

        epoll.register(server.fileno(), select.EPOLLIN)

        while True:
            events = epoll.poll()

            for fd, event in events:
                # Accepter, lire, traiter, r√©pondre
                # TOUT dans le m√™me thread !
                # Pas de locks n√©cessaires (single-thread)
                self.handle_event(fd, event)

    def handle_command(self, command):
        """Traite une commande Redis"""
        parts = command.split()

        if parts[0] == b'GET':
            key = parts[1]
            value = self.data.get(key, b'(nil)')
            return value

        elif parts[0] == b'SET':
            key = parts[1]
            value = parts[2]
            self.data[key] = value  # Pas de lock n√©cessaire !
            return b'OK'

# Pourquoi single-thread ?
# - Pas de contention sur les locks
# - Code simple (pas de sync)
# - Performance : 100000+ ops/sec
# - Toutes les op√©rations sont rapides (< 1ms)
```

**Pourquoi Redis est si rapide ?**

1. **Single-thread** : Pas de context switching, pas de locks
2. **Event-driven** : I/O non-bloquant
3. **In-memory** : Aucune I/O disque bloquante
4. **Op√©rations atomiques** : Pas de transactions complexes

```
Redis performance :
- 100000+ GET/SET par seconde
- Latence < 1ms
- 10000+ connexions simultan√©es
- RAM : ~50 MB (base + donn√©es)
```

### 3. Node.js (JavaScript backend)

**Node.js** : Event loop single-threaded

```javascript
// Serveur HTTP Node.js (event-driven)
const http = require('http');

// SINGLE THREAD, mais g√®re des milliers de connexions
const server = http.createServer((req, res) => {
    // Cette fonction est appel√©e pour CHAQUE requ√™te
    // Mais ne bloque jamais l'event loop

    // I/O non-bloquant (async)
    fs.readFile('/data.json', (err, data) => {
        // Callback appel√© quand le fichier est lu
        // Pendant ce temps, d'autres requ√™tes sont trait√©es
        res.writeHead(200, {'Content-Type': 'application/json'});
        res.end(data);
    });

    // Cette fonction retourne IMM√âDIATEMENT
    // Le serveur peut traiter d'autres requ√™tes
});

server.listen(3000);

// Performance :
// - 10000+ req/sec
// - 100 MB RAM
// - 1 CPU core
```

**√âquivalent Python avec asyncio** :

```python
import asyncio

async def handle_client(reader, writer):
    """Handler async (non-bloquant)"""
    # Lecture async (ne bloque pas l'event loop)
    data = await reader.read(1024)

    # Traitement async
    response = await process_data(data)

    # √âcriture async
    writer.write(response)
    await writer.drain()

    writer.close()

async def main():
    # Serveur async
    server = await asyncio.start_server(
        handle_client,
        '0.0.0.0',
        8080
    )

    async with server:
        await server.serve_forever()

# UN SEUL THREAD, des milliers de connexions
asyncio.run(main())
```

### 4. Chat en temps r√©el (Discord, Slack)

```python
import asyncio
import websockets

class ChatServer:
    """Serveur de chat avec WebSocket (async)"""

    def __init__(self):
        self.clients = set()  # Tous les clients connect√©s

    async def handler(self, websocket, path):
        """G√®re un client WebSocket"""
        # Ajouter le client
        self.clients.add(websocket)
        print(f"Client connect√©. Total: {len(self.clients)}")

        try:
            # Boucle de r√©ception (async)
            async for message in websocket:
                # Broadcast √† tous les clients
                await self.broadcast(message, websocket)

        finally:
            # Retirer le client
            self.clients.remove(websocket)
            print(f"Client d√©connect√©. Total: {len(self.clients)}")

    async def broadcast(self, message, sender):
        """Envoie un message √† tous les clients (sauf l'√©metteur)"""
        # Envoyer en parall√®le √† tous les clients
        tasks = []
        for client in self.clients:
            if client != sender:
                tasks.append(client.send(message))

        # Attendre toutes les envois (async)
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)

    async def start(self):
        """D√©marre le serveur"""
        async with websockets.serve(self.handler, '0.0.0.0', 8765):
            print("Serveur de chat d√©marr√© sur :8765")
            await asyncio.Future()  # Run forever

# Capacit√© :
# - 100000+ clients connect√©s simultan√©ment
# - Un seul processus/thread
# - RAM : ~1 GB (10 KB par client)
# - Latence : < 10ms

# Discord utilise ce mod√®le (Elixir/Erlang, principes similaires)
# pour g√©rer des MILLIONS d'utilisateurs connect√©s
```

## Quand utiliser I/O bloquant vs non-bloquant ?

### Utiliser I/O BLOQUANT quand :

‚úÖ **Peu de connexions** (< 100 simultan√©es)

```python
# API interne avec 10-20 clients max
def internal_api_server():
    # Thread-per-connection est OK
    server = ThreadedTCPServer(('localhost', 9999), RequestHandler)
    server.serve_forever()
```

‚úÖ **Code simple prioritaire**

```python
# Script one-off ou prototype
def download_file(url):
    response = requests.get(url)  # Bloquant, mais simple
    with open('file.dat', 'wb') as f:
        f.write(response.content)
```

‚úÖ **CPU-bound plut√¥t que I/O-bound**

```python
# Chaque requ√™te fait du calcul intensif
def handle_request(data):
    # Calcul qui prend 5 secondes
    result = heavy_computation(data)
    return result

# I/O bloquant + thread pool est adapt√©
```

‚úÖ **Int√©gration avec code legacy bloquant**

```python
# Biblioth√®que tierce qui bloque
import legacy_library

def use_legacy():
    result = legacy_library.blocking_call()
    # Difficile de rendre async sans r√©√©crire
```

### Utiliser I/O NON-BLOQUANT quand :

‚úÖ **Beaucoup de connexions** (> 1000 simultan√©es)

```python
# Serveur web public, API publique
# WebSocket server avec 10000+ clients
async def websocket_server():
    # Event loop g√®re tous les clients efficacement
    async with websockets.serve(handler, '0.0.0.0', 8080):
        await asyncio.Future()
```

‚úÖ **I/O-bound (r√©seau, disque)**

```python
# Serveur proxy qui fait beaucoup d'I/O r√©seau
async def proxy_handler(request):
    # Appel r√©seau 1
    user_data = await fetch_user_service(request.user_id)

    # Appel r√©seau 2 (en parall√®le)
    products = await fetch_product_service(request.query)

    # Appel r√©seau 3
    recommendations = await fetch_recommendations(user_data)

    return merge(user_data, products, recommendations)
```

‚úÖ **Latence critique**

```python
# Trading haute fr√©quence
async def trading_engine():
    # Chaque milliseconde compte
    # Event loop = latence pr√©visible
    async for market_data in stream:
        await process_order(market_data)
```

‚úÖ **Temps r√©el**

```python
# Gaming server, streaming, chat
async def game_server():
    # Besoin de g√©rer 10000+ joueurs simultan√©ment
    # avec latence < 50ms
    while True:
        await broadcast_game_state()
        await asyncio.sleep(0.016)  # 60 FPS
```

## Patterns hybrides

### 1. Async + Thread Pool pour CPU

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

# Event loop pour I/O
# Thread pool pour CPU

async def handle_request(data):
    """Handler async avec calcul CPU dans thread pool"""
    # I/O async (non-bloquant)
    raw_data = await fetch_from_database(data.id)

    # CPU-bound dans thread pool (pour ne pas bloquer event loop)
    loop = asyncio.get_event_loop()
    executor = ThreadPoolExecutor(max_workers=4)

    result = await loop.run_in_executor(
        executor,
        heavy_computation,  # Fonction CPU-bound
        raw_data
    )

    # I/O async
    await save_to_database(result)

    return result

def heavy_computation(data):
    """Calcul intensif (bloquant)"""
    # Tourne dans un thread s√©par√©
    return complex_algorithm(data)

# Meilleur des deux mondes :
# - I/O async pour scalabilit√©
# - Threads pour CPU-bound
```

### 2. Gevent (Green Threads)

```python
from gevent import monkey
monkey.patch_all()  # Patch stdlib pour rendre async

from gevent.pool import Pool
from gevent.server import StreamServer
import requests

# Code qui RESSEMBLE √† du bloquant
# Mais tourne en async gr√¢ce √† gevent
def handle_client(sock, addr):
    """Handler qui ressemble bloquant mais est async"""
    # Ces appels SEMBLENT bloquants
    # Mais gevent les rend async automatiquement
    data = sock.recv(1024)

    # Requ√™te HTTP (monkey-patched = async)
    response = requests.get('http://api.example.com')

    sock.send(response.content)
    sock.close()

# Serveur avec pool de greenlets
pool = Pool(10000)  # 10000 "threads" l√©gers
server = StreamServer(('0.0.0.0', 8080), handle_client, spawn=pool)
server.serve_forever()

# AVANTAGES :
# ‚úÖ Code simple (style bloquant)
# ‚úÖ Performance async
# ‚úÖ Scalabilit√© (10000+ connexions)

# INCONV√âNIENTS :
# ‚ùå Monkey-patching peut casser certaines libs
# ‚ùå Moins de contr√¥le qu'asyncio
```

## Debugging et profiling

### Debugging I/O bloquant

```python
import socket
import sys
import traceback

def debug_blocking_recv(sock, size):
    """recv() avec debug de blocage"""
    print(f"[DEBUG] D√©but recv({size})")
    print(f"[DEBUG] Stack trace:")
    traceback.print_stack()

    import time
    start = time.time()

    data = sock.recv(size)

    duration = time.time() - start
    print(f"[DEBUG] recv() bloqu√© pendant {duration:.3f}s")

    return data

# Utilisation pour identifier o√π le code bloque
```

### Profiling event loop

```python
import asyncio
import time

class ProfilingEventLoop:
    """Event loop avec profiling"""

    def __init__(self):
        self.task_times = {}

    async def run_task(self, name, coro):
        """Ex√©cute une coroutine avec timing"""
        start = time.time()

        result = await coro

        duration = time.time() - start
        self.task_times[name] = duration

        if duration > 0.1:  # > 100ms
            print(f"‚ö†Ô∏è  Task '{name}' trop lent: {duration:.3f}s")

        return result

    def print_report(self):
        """Affiche le rapport"""
        print("\n=== Event Loop Profiling ===")
        for name, duration in sorted(self.task_times.items(), key=lambda x: x[1], reverse=True):
            print(f"{name}: {duration*1000:.2f}ms")

# Utilisation
profiler = ProfilingEventLoop()

async def main():
    await profiler.run_task('fetch_user', fetch_user())
    await profiler.run_task('fetch_products', fetch_products())

    profiler.print_report()
```

## R√©capitulatif

### Points cl√©s

üéØ **I/O Bloquant** :
- Simple √† comprendre et coder
- Limit√© en scalabilit√© (threads)
- Bon pour peu de connexions ou CPU-bound

üéØ **I/O Non-bloquant** :
- Scalable (10000+ connexions)
- Plus complexe (machine √† √©tats)
- Id√©al pour I/O-bound et temps r√©el

üéØ **Choix d√©pend de** :
- Nombre de connexions simultan√©es
- I/O-bound vs CPU-bound
- Simplicit√© vs Performance
- Comp√©tences de l'√©quipe

### Tableau d√©cisionnel rapide

| Crit√®re | Bloquant | Non-bloquant |
|---------|----------|--------------|
| < 100 connexions | ‚úÖ | ‚ö†Ô∏è Overkill |
| 100-1000 connexions | ‚ö†Ô∏è Limite | ‚úÖ |
| > 1000 connexions | ‚ùå | ‚úÖ |
| Code simple | ‚úÖ | ‚ùå |
| Performance max | ‚ùå | ‚úÖ |
| CPU-bound | ‚úÖ | ‚ö†Ô∏è + threads |
| I/O-bound | ‚ö†Ô∏è | ‚úÖ |
| Temps r√©el | ‚ùå | ‚úÖ |

## Prochaines √©tapes

Maintenant que vous comprenez I/O bloquant vs non-bloquant, nous allons approfondir :

- **Section 8.6** : Multiplexage (select, poll, epoll, kqueue) - Comment surveiller plusieurs sockets efficacement
- **Section 8.7** : Programmation asynchrone et event-driven - asyncio, patterns modernes
- **Section 8.8** : R√©silience et fiabilit√© applicative

---


‚è≠Ô∏è [Multiplexage : select, poll, epoll](/08-programmation-reseau/06-multiplexage.md)
