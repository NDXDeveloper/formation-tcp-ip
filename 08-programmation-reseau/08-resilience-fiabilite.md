üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.8 R√©silience et fiabilit√© applicative

## Introduction

Dans un monde o√π les applications distribu√©es sont la norme, la r√©silience r√©seau n'est plus une option mais une n√©cessit√©. M√™me avec TCP qui garantit la livraison des paquets, une application peut √©chouer de multiples fa√ßons : serveurs surcharg√©s, timeouts r√©seau, pannes transitoires, d√©gradations de performance. **La diff√©rence entre une application amateur et une application production-ready r√©side souvent dans sa capacit√© √† g√©rer √©l√©gamment ces d√©faillances.**

Cette section explore les strat√©gies et patterns essentiels pour construire des applications r√©seau robustes qui survivent aux conditions r√©elles d'exploitation.

---

## Pourquoi la r√©silience est-elle critique ?

### Le r√©seau n'est pas fiable

Contrairement √† un appel de fonction local qui r√©ussit ou √©choue de mani√®re d√©terministe, une requ√™te r√©seau traverse un syst√®me distribu√© complexe :

```
Client ‚Üí DNS ‚Üí Load Balancer ‚Üí Reverse Proxy ‚Üí Application ‚Üí Database
          ‚Üì         ‚Üì              ‚Üì              ‚Üì            ‚Üì
       Timeout   Saturation    Rate limit    Out of Memory  Slow query
```

**Chaque composant peut √©chouer de diff√©rentes mani√®res** :
- **√âchecs francs** : connexion refus√©e, timeout r√©seau
- **√âchecs silencieux** : paquets perdus, black holes r√©seau
- **D√©gradations** : latence √©lev√©e, d√©bit r√©duit
- **√âchecs partiels** : certaines requ√™tes passent, d'autres non

### Cas r√©el : L'effet domino d'AWS US-EAST-1 (2017)

Lors d'une panne majeure, une simple erreur de saisie dans une commande de maintenance a entra√Æn√© :
1. Arr√™t de serveurs S3 critiques
2. Surcharge des serveurs restants
3. Cascade de timeouts dans les applications clientes
4. Saturation des retry mechanisms mal configur√©s
5. Amplification de la charge (retry storms)
6. Panne de services d√©pendants pourtant "ind√©pendants"

**Cons√©quence** : Des milliers d'applications sont tomb√©es non pas √† cause de la panne S3, mais parce qu'elles n'√©taient pas con√ßues pour g√©rer cette d√©faillance.

---

## Les huit d√©faillances de Deutsch

Peter Deutsch a formul√© les **"Fallacies of Distributed Computing"**, hypoth√®ses erron√©es que font souvent les d√©veloppeurs :

1. **Le r√©seau est fiable** ‚ùå
   - R√©alit√© : paquets perdus, connexions interrompues

2. **La latence est nulle** ‚ùå
   - R√©alit√© : 1ms en datacenter, 100ms+ intercontinental

3. **La bande passante est infinie** ‚ùå
   - R√©alit√© : congestion, throttling, quotas

4. **Le r√©seau est s√©curis√©** ‚ùå
   - R√©alit√© : man-in-the-middle, injection, spoofing

5. **La topologie ne change pas** ‚ùå
   - R√©alit√© : autoscaling, d√©ploiements, pannes

6. **Il y a un seul administrateur** ‚ùå
   - R√©alit√© : multi-cloud, fournisseurs tiers

7. **Le co√ªt de transport est nul** ‚ùå
   - R√©alit√© : facturation au trafic, limites de quota

8. **Le r√©seau est homog√®ne** ‚ùå
   - R√©alit√© : protocoles vari√©s, versions diff√©rentes

**Chaque erreur de conception bas√©e sur ces hypoth√®ses cr√©e des vuln√©rabilit√©s en production.**

---

## Principes fondamentaux de la r√©silience

### 1. Fail Fast vs Fail Safe

Deux philosophies s'opposent :

**Fail Fast (√âchouer rapidement)**
```python
# Bon pour : APIs synchrones, interfaces utilisateur
def get_user(user_id, timeout=2.0):
    try:
        response = http.get(f"/users/{user_id}", timeout=timeout)
        return response.json()
    except Timeout:
        raise UserServiceUnavailable("Service timeout")
```

**Avantages** :
- Lib√®re rapidement les ressources
- √âvite les threads/connexions bloqu√©s
- Feedback imm√©diat √† l'utilisateur

**Fail Safe (D√©grader gracieusement)**
```python
# Bon pour : syst√®mes critiques, donn√©es en cache acceptable
def get_user(user_id):
    try:
        return fetch_from_api(user_id, timeout=2.0)
    except Exception:
        cached = get_from_cache(user_id)
        if cached:
            return cached  # Donn√©es potentiellement p√©rim√©es mais valides
        return get_default_user()  # Utilisateur anonyme
```

**Avantages** :
- Exp√©rience utilisateur continu√©e
- Donn√©es partielles mieux que rien
- Absorbe les pannes transitoires

**Cas d'usage r√©el (Netflix)** : Quand l'API de recommandation √©choue, Netflix affiche des recommandations g√©n√©riques en cache plut√¥t qu'une page d'erreur. L'utilisateur peut toujours naviguer et regarder du contenu.

### 2. Isolation des d√©faillances (Bulkheading)

Inspir√© des compartiments √©tanches des navires, ce pattern isole les ressources pour √©viter qu'une d√©faillance ne contamine tout le syst√®me.

**Exemple : Pool de connexions s√©par√©s**
```javascript
// Anti-pattern : un seul pool pour tous les services
const pool = new ConnectionPool({ maxConnections: 100 });

// Si le service lent sature le pool, TOUS les services sont impact√©s
await pool.query('slow-service', ...);  // Bloque 90 connexions
await pool.query('fast-service', ...);  // Plus de connexions disponibles !
```

```javascript
// Pattern : pools isol√©s par service
const pools = {
    userService: new ConnectionPool({ max: 30 }),
    paymentService: new ConnectionPool({ max: 20 }),
    analyticsService: new ConnectionPool({ max: 10 })  // Non-critique
};

// La saturation d'analytics n'impacte pas payment
```

**Cas d'usage r√©el (Microservices)** :
- Threads/goroutines d√©di√©s par d√©pendance externe
- Rate limiters s√©par√©s
- Timeouts diff√©renci√©s selon la criticit√©

### 3. D√©gradation gracieuse

Prioriser les fonctionnalit√©s essentielles en cas de surcharge.

**Exemple : E-commerce sous charge**
```python
class CheckoutService:
    def process_order(self, cart, user):
        # Critique : enregistrer la commande
        order = self.save_order(cart, user)  # Timeout: 5s

        try:
            # Important : calculer les points de fid√©lit√©
            points = self.loyalty_service.calculate(order, timeout=1.0)
            self.loyalty_service.credit(user, points, timeout=1.0)
        except Timeout:
            # D√©grader : on calculera les points en asynchrone
            self.queue_loyalty_calculation(order.id)

        try:
            # Nice-to-have : recommandations personnalis√©es
            recommendations = self.ml_service.get_recommendations(
                user, timeout=0.5
            )
        except Timeout:
            # D√©grader : recommandations g√©n√©riques
            recommendations = self.get_popular_items()

        return {
            'order': order,
            'loyalty_points': points or 'pending',
            'recommendations': recommendations
        }
```

**Hi√©rarchie de criticit√©** :
1. **Must-have** : Transaction financi√®re, commande
2. **Should-have** : Email de confirmation, mise √† jour de stock
3. **Nice-to-have** : Recommandations, analytics

### 4. Idempotence

Une op√©ration idempotente produit le m√™me r√©sultat qu'elle soit ex√©cut√©e une ou plusieurs fois.

**Pourquoi c'est crucial pour la r√©silience** :
- Permet de retenter (retry) sans effet de bord
- G√®re les duplications r√©seau
- Simplifie la r√©conciliation

**Exemple : API de paiement**
```http
POST /payments HTTP/1.1
Content-Type: application/json
Idempotency-Key: 7d8f6e42-3a9b-4c5d-8e2f-1a3b4c5d6e7f

{
  "amount": 99.99,
  "currency": "EUR",
  "customer_id": "cust_123"
}
```

```python
# C√¥t√© serveur
def process_payment(amount, customer_id, idempotency_key):
    # V√©rifier si d√©j√† trait√©
    existing = db.query(
        "SELECT * FROM payments WHERE idempotency_key = ?",
        idempotency_key
    )

    if existing:
        return existing  # Retourner le r√©sultat existant

    # Nouveau paiement
    payment = charge_customer(amount, customer_id)
    db.insert({
        'idempotency_key': idempotency_key,
        'payment_id': payment.id,
        'status': payment.status
    })

    return payment
```

**Cas d'usage r√©els** :
- **Stripe** : Toutes les APIs de mutation acceptent un `Idempotency-Key`
- **AWS S3** : PUT sur la m√™me cl√© est idempotent
- **Kafka** : Producers avec `enable.idempotence=true`

### 5. Observabilit√© et monitoring

**On ne peut pas am√©liorer ce qu'on ne mesure pas.**

**M√©triques essentielles** :
```go
type NetworkMetrics struct {
    RequestDuration    histogram  // Latence P50, P95, P99
    ErrorRate          counter    // % d'√©checs
    TimeoutRate        counter    // % de timeouts
    RetryCount         counter    // Nombre de retries
    CircuitBreakerState gauge     // open/half-open/closed
    ConnectionPoolUsage gauge     // % de connexions utilis√©es
}
```

**Exemple d'impl√©mentation (Go avec Prometheus)** :
```go
var (
    requestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Buckets: []float64{.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5},
        },
        []string{"service", "endpoint", "status"},
    )

    errorRate = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_request_errors_total",
        },
        []string{"service", "error_type"},
    )
)

func makeRequest(service, endpoint string) {
    start := time.Now()

    resp, err := http.Get(endpoint)
    duration := time.Since(start).Seconds()

    status := "success"
    if err != nil {
        status = "error"
        errorRate.WithLabelValues(service, classifyError(err)).Inc()
    }

    requestDuration.WithLabelValues(service, endpoint, status).Observe(duration)
}
```

---

## Architecture de r√©silience en couches

Une application r√©siliente combine plusieurs niveaux de d√©fense :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Application Layer                              ‚îÇ
‚îÇ  ‚Ä¢ Circuit Breakers                             ‚îÇ
‚îÇ  ‚Ä¢ Retry Logic                                  ‚îÇ
‚îÇ  ‚Ä¢ Fallbacks                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Network Layer                                  ‚îÇ
‚îÇ  ‚Ä¢ Connection Timeouts                          ‚îÇ
‚îÇ  ‚Ä¢ Read/Write Timeouts                          ‚îÇ
‚îÇ  ‚Ä¢ Keep-Alive                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Infrastructure Layer                           ‚îÇ
‚îÇ  ‚Ä¢ Load Balancers                               ‚îÇ
‚îÇ  ‚Ä¢ Health Checks                                ‚îÇ
‚îÇ  ‚Ä¢ Auto-scaling                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Protocol Layer                                 ‚îÇ
‚îÇ  ‚Ä¢ TCP Retransmissions                          ‚îÇ
‚îÇ  ‚Ä¢ Congestion Control                           ‚îÇ
‚îÇ  ‚Ä¢ Flow Control                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Chaque couche compense les limites de la couche inf√©rieure.**

---

## Patterns de r√©silience : Vue d'ensemble

Les sous-sections suivantes d√©tailleront chaque pattern, mais voici un aper√ßu :

### Timeouts (8.8.1)
D√©finir des limites temporelles pour √©viter les blocages infinis.

**Types** :
- **Connection timeout** : temps max pour √©tablir une connexion
- **Read timeout** : temps max pour recevoir des donn√©es
- **Write timeout** : temps max pour envoyer des donn√©es

### Retry Logic et Backoff Exponentiel (8.8.2)
Retenter intelligemment les op√©rations √©chou√©es.

**Strat√©gies** :
- **Immediate retry** : pour erreurs transitoires
- **Exponential backoff** : 1s, 2s, 4s, 8s...
- **Jitter** : al√©atoire pour √©viter la synchronisation

### Circuit Breakers (8.8.3)
Arr√™ter temporairement les appels vers un service d√©faillant.

**√âtats** :
- **Closed** : trafic normal
- **Open** : blocage des requ√™tes
- **Half-Open** : test de r√©cup√©ration

### Keep-Alive et Connexions Persistantes (8.8.4)
R√©utiliser les connexions pour √©viter le co√ªt du handshake.

**B√©n√©fices** :
- R√©duit la latence (pas de 3-way handshake)
- Diminue la charge serveur
- Am√©liore le throughput

---

## Cas d'usage complet : API Gateway r√©silient

Voici comment tous ces patterns s'assemblent dans une architecture r√©elle :

```python
from circuit_breaker import CircuitBreaker
from retry import retry_with_backoff
import httpx

class ResilientAPIGateway:
    def __init__(self):
        # Pool de connexions avec keep-alive
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(
                connect=2.0,    # Connection timeout
                read=5.0,       # Read timeout
                write=5.0,      # Write timeout
                pool=10.0       # Pool acquisition timeout
            ),
            limits=httpx.Limits(
                max_connections=100,
                max_keepalive_connections=20
            ),
            http2=True  # Multiplexage pour r√©duire les connexions
        )

        # Circuit breakers par service
        self.breakers = {
            'user-service': CircuitBreaker(
                failure_threshold=5,
                recovery_timeout=30,
                expected_exception=httpx.HTTPError
            ),
            'payment-service': CircuitBreaker(
                failure_threshold=3,  # Plus strict pour paiements
                recovery_timeout=60
            )
        }

    @retry_with_backoff(
        max_attempts=3,
        base_delay=1.0,
        max_delay=10.0,
        exponential_base=2,
        jitter=True
    )
    async def call_service(self, service_name, endpoint, **kwargs):
        breaker = self.breakers[service_name]

        # Le circuit breaker bloque si le service est down
        with breaker:
            try:
                response = await self.client.get(
                    f"http://{service_name}{endpoint}",
                    **kwargs
                )
                response.raise_for_status()
                return response.json()

            except httpx.TimeoutException:
                # Timeout : on retry (g√©r√© par le d√©corateur)
                raise

            except httpx.HTTPStatusError as e:
                if e.response.status_code >= 500:
                    # Erreur serveur : on retry
                    raise
                else:
                    # Erreur client (4xx) : pas de retry
                    return self.handle_client_error(e)

    async def get_user_with_fallback(self, user_id):
        try:
            return await self.call_service(
                'user-service',
                f'/users/{user_id}'
            )
        except Exception as e:
            # Fallback : utilisateur en cache ou anonyme
            cached = await self.cache.get(f'user:{user_id}')
            if cached:
                return {'source': 'cache', **cached}

            # Derni√®re d√©fense : utilisateur anonyme
            return {
                'source': 'fallback',
                'id': user_id,
                'name': 'Anonymous User',
                'error': str(e)
            }
```

**Ce que fait ce code** :
1. **Timeouts** √† plusieurs niveaux (connexion, lecture, √©criture)
2. **Keep-alive** avec pool de connexions r√©utilisables
3. **Circuit breakers** pour isoler les services d√©faillants
4. **Retry avec backoff exponentiel** pour les erreurs transitoires
5. **Fallback** vers cache ou donn√©es par d√©faut
6. **HTTP/2** pour le multiplexage

---

## Anti-patterns courants √† √©viter

### ‚ùå Retry infini sans limite

```python
# DANGER : Peut cr√©er des retry storms
def fetch_data(url):
    while True:
        try:
            return requests.get(url, timeout=30)
        except Exception:
            time.sleep(1)  # Retry imm√©diat
            continue  # Boucle infinie !
```

**Cons√©quences** :
- Threads/processus bloqu√©s ind√©finiment
- Amplification de charge sur service d√©faillant
- √âpuisement des ressources

### ‚ùå Timeout trop long

```python
# Anti-pattern : timeout de 60 secondes
response = requests.get(url, timeout=60)
```

**Probl√®me** : Un utilisateur web n'attendra jamais 60 secondes. Le timeout doit refl√©ter les attentes utilisateur (g√©n√©ralement 2-5s pour une API).

### ‚ùå Absence de jitter dans les retries

```python
# Tous les clients retry en m√™me temps !
for attempt in range(3):
    try:
        return call_api()
    except:
        time.sleep(2 ** attempt)  # 1s, 2s, 4s - synchronis√© !
```

**Cons√©quence** : Thundering herd - tous les clients attaquent simultan√©ment apr√®s un d√©lai identique.

**Solution** : Ajouter du jitter al√©atoire
```python
import random
time.sleep((2 ** attempt) + random.uniform(0, 1))
```

### ‚ùå Ignorer les codes HTTP 4xx

```python
# Anti-pattern : retry sur toutes les erreurs
@retry(tries=3)
def get_resource(id):
    response = requests.get(f'/api/resources/{id}')
    response.raise_for_status()
    return response.json()
```

**Probl√®me** : Un 404 (Not Found) ou 400 (Bad Request) ne sera jamais r√©solu par un retry. On gaspille des ressources.

**Solution** : Retry uniquement sur 5xx et timeouts
```python
def should_retry(exception):
    if isinstance(exception, requests.Timeout):
        return True
    if isinstance(exception, requests.HTTPError):
        return 500 <= exception.response.status_code < 600
    return False

@retry(retry=retry_if_exception(should_retry))
def get_resource(id):
    ...
```

---

## M√©triques de r√©silience

**SLI/SLO (Service Level Indicators/Objectives)** :

```yaml
# Exemple de SLO pour une API
availability:
  target: 99.9%  # "Three nines"
  measurement: success_rate over 30d rolling window

latency:
  p50: < 100ms
  p95: < 500ms
  p99: < 1000ms

error_budget:
  monthly: 0.1% = 43.2 minutes de downtime
  alert_if: > 50% budget consumed in 24h
```

**Calcul du Error Budget** :
```
Downtime autoris√© (99.9%) = 43.2 min/mois
Downtime actuel = 15 min en 2 semaines
Budget consomm√© = 15/43.2 = 34.7%
```

---

## Checklist de r√©silience pour d√©veloppeurs

Avant de d√©ployer une application r√©seau en production, v√©rifiez :

- [ ] **Timeouts configur√©s** sur toutes les op√©rations r√©seau
- [ ] **Retry logic** avec backoff exponentiel et jitter
- [ ] **Circuit breakers** sur les d√©pendances externes
- [ ] **Connection pooling** avec limites appropri√©es
- [ ] **Keep-alive** activ√© pour connexions persistantes
- [ ] **Fallbacks** d√©finis pour fonctionnalit√©s non-critiques
- [ ] **Idempotence** garantie pour op√©rations de mutation
- [ ] **Monitoring** avec m√©triques de latence et taux d'erreur
- [ ] **Rate limiting** pour prot√©ger contre la surcharge
- [ ] **Bulkheading** pour isoler les ressources
- [ ] **Logging** structur√© pour diagnostiquer les pannes
- [ ] **Chaos engineering** test√© (simulation de pannes)

---

## Conclusion

La r√©silience applicative n'est pas un ajout optionnel, c'est un **requirement fondamental** pour toute application r√©seau moderne. Les techniques pr√©sent√©es dans cette section - timeouts, retries, circuit breakers, keep-alive - forment un arsenal complet pour g√©rer les d√©faillances in√©vitables des syst√®mes distribu√©s.

**Points cl√©s √† retenir** :
1. Le r√©seau √©chouera - concevez pour l'√©chec, pas pour le succ√®s
2. Combinez plusieurs patterns de r√©silience en couches
3. Mesurez tout - l'observabilit√© est la cl√© de l'am√©lioration
4. Testez les pannes en environnement de test (chaos engineering)
5. D√©gradez gracieusement plut√¥t que d'√©chouer compl√®tement

Les sections suivantes d√©tailleront chacune de ces techniques avec des impl√©mentations concr√®tes et des exemples de code dans diff√©rents langages.

---


‚è≠Ô∏è [Timeouts : lecture, √©criture, connexion](/08-programmation-reseau/08.1-timeouts.md)
