ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 3.12.6 Implications pour les architectures cloud et microservices

## Introduction

Les protocoles de routage que nous avons Ã©tudiÃ©s (RIP, OSPF, BGP) ont Ã©tÃ© conÃ§us dans les annÃ©es 1980-1990 pour des rÃ©seaux **relativement stables** : des routeurs et des serveurs physiques qui restaient en place pendant des annÃ©es.

Mais le monde a changÃ©. Aujourd'hui, nous avons :
- Des **applications cloud** qui s'exÃ©cutent sur des serveurs virtuels
- Des **conteneurs** qui dÃ©marrent et s'arrÃªtent en quelques secondes
- Des **microservices** oÃ¹ une application est divisÃ©e en dizaines de petits services
- Des **infrastructures Ã©phÃ©mÃ¨res** oÃ¹ rien n'est permanent

**Analogie** : C'est comme passer d'une ville avec des bÃ¢timents permanents Ã  une fÃªte foraine oÃ¹ les stands apparaissent et disparaissent constamment. Les protocoles de routage traditionnels sont comme des cartes en papier (mise Ã  jour annuelle), alors que le cloud a besoin de GPS en temps rÃ©el.

Cette section explore comment les concepts de routage s'adaptent Ã  ces nouvelles architectures.

## RÃ©seaux traditionnels vs Cloud : Un changement de paradigme

### CaractÃ©ristiques des rÃ©seaux traditionnels

**Infrastructure physique** :
```
Datacenter on-premise :
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Serveur 1 : 192.168.1.10        â”‚ â† MÃªme IP pendant des annÃ©es
â”‚ Serveur 2 : 192.168.1.11        â”‚
â”‚ Serveur 3 : 192.168.1.12        â”‚
â”‚ ...                             â”‚
â”‚ Configuration manuelle          â”‚
â”‚ Changements rares               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**PropriÃ©tÃ©s** :
- Serveurs physiques stables
- Adresses IP fixes
- Topologie connue et documentÃ©e
- Changements planifiÃ©s (maintenance)
- Ã‰chelle de temps : mois/annÃ©es

**Analogie** : Une bibliothÃ¨que traditionnelle
- Les Ã©tagÃ¨res sont fixes
- Les livres ont des emplacements permanents
- La signalÃ©tique ne change pas
- Vous pouvez mÃ©moriser oÃ¹ tout se trouve

### CaractÃ©ristiques du cloud et des microservices

**Infrastructure dynamique** :
```
Cloud moderne :
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pod 1 : 10.244.1.5  (crÃ©Ã©)      â”‚
â”‚ Pod 2 : 10.244.2.8  (dÃ©truit)   â”‚ â† IPs changent constamment
â”‚ Pod 3 : 10.244.1.9  (migrÃ©)     â”‚
â”‚ Pod 4 : 10.244.3.2  (scalÃ©)     â”‚
â”‚ ...                             â”‚
â”‚ Auto-scaling                    â”‚
â”‚ Changements continuels          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**PropriÃ©tÃ©s** :
- Instances virtuelles Ã©phÃ©mÃ¨res
- Adresses IP dynamiques
- Topologie en constante Ã©volution
- Changements automatiques (auto-scaling)
- Ã‰chelle de temps : secondes/minutes

**Analogie** : Une application de livraison de repas
- Les livreurs (conteneurs) sont mobiles
- Leurs positions changent constamment
- Nouveaux livreurs rejoignent selon la demande
- Le systÃ¨me doit tracker tout en temps rÃ©el

### Tableau comparatif

| Aspect | Traditionnel | Cloud/Microservices |
|--------|--------------|---------------------|
| **Infrastructure** | Physique | Virtuelle/Conteneurs |
| **DurÃ©e de vie** | AnnÃ©es | Secondes Ã  heures |
| **Adresses IP** | Statiques | Dynamiques |
| **Changements** | Rares, planifiÃ©s | FrÃ©quents, automatiques |
| **Ã‰chelle** | Centaines de serveurs | Milliers d'instances |
| **Topologie** | Stable | Fluide |
| **Configuration** | Manuelle | AutomatisÃ©e (IaC) |
| **DÃ©couverte** | Statique (DNS) | Dynamique (Service Discovery) |

## Les dÃ©fis du routage dans le cloud

### 1. DynamicitÃ© extrÃªme

**ProblÃ¨me** : Les instances apparaissent et disparaissent en permanence.

**Exemple concret** :
```
08h00 : Application e-commerce dÃ©marre
        - 10 instances de service API
        - 5 instances de base de donnÃ©es

12h00 : Pic de trafic (heure de dÃ©jeuner)
        - Auto-scaling dÃ©clenchÃ©
        - +50 instances API en 2 minutes
        - Nouvelles IPs : 10.244.5.x, 10.244.6.x, ...

13h30 : Trafic diminue
        - Scale down automatique
        - 30 instances terminÃ©es

Comment le rÃ©seau suit-il ces changements ?
```

**Solutions traditionnelles inadaptÃ©es** :
- OSPF : Convergence en secondes â†’ Trop lent pour des conteneurs qui vivent 30s
- Routes statiques : Impossibles Ã  maintenir manuellement
- DNS classique : Cache trop long (TTL de minutes/heures)

**Solutions modernes** :
- Service discovery dynamique (Consul, etcd)
- Load balancers avec health checks rapides
- Service mesh (Istio, Linkerd)

### 2. Ã‰chelle massive

**ProblÃ¨me** : Des milliers d'instances communiquent entre elles.

**Calcul de connectivitÃ©** :
```
Application monolithique :
- 1 serveur web â†’ 1 serveur DB
= 1 connexion Ã  gÃ©rer

Architecture microservices :
- 100 instances service A
- 100 instances service B
- 100 instances service C

Connexions potentielles : 100 Ã— 100 Ã— 100 = 1 000 000 !
```

**ProblÃ¨mes** :
- Table de routage gigantesque
- Mises Ã  jour constantes
- Consommation de ressources rÃ©seau Ã©levÃ©e

**Solutions** :
- Overlay networks (VXLAN)
- Service mesh avec sidecar proxies
- Abstractions au niveau L7 (applicatif)

### 3. Communication Est-Ouest massive

**Trafic traditionnel (Nord-Sud)** :
```
Internet
   â†“
Firewall
   â†“
Load Balancer
   â†“
Serveurs

Trafic : Principalement "Nord-Sud" (clients â†’ serveurs)
```

**Trafic microservices (Est-Ouest)** :
```
    Service A
   â†™ â†“ â†˜
Service B â†’ Service C â†’ Service D
   â†“         â†™ â†“ â†˜
Service E  Service F  Service G

Trafic : Principalement "Est-Ouest" (service â†’ service)
75-80% du trafic dans le datacenter !
```

**Implications** :
- Les protocoles de routage traditionnels optimisent pour Nord-Sud
- Le routage Est-Ouest nÃ©cessite des approches diffÃ©rentes
- Latence inter-service critique
- SÃ©curitÃ© entre services importante (zero-trust)

### 4. Multi-tenancy et isolation

**ProblÃ¨me** : Plusieurs clients partagent la mÃªme infrastructure.

```
Cloud Provider Infrastructure
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tenant A : 10.1.0.0/16          â”‚
â”‚ Tenant B : 10.1.0.0/16 (mÃªme!)  â”‚ â† Conflit d'adressage
â”‚ Tenant C : 10.1.0.0/16          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Besoins** :
- Isolation rÃ©seau complÃ¨te entre tenants
- MÃªmes espaces d'adressage IP possibles
- Performance non impactÃ©e par la segmentation

**Solutions** :
- VRF (Virtual Routing and Forwarding)
- VXLAN avec VNI (VXLAN Network Identifier)
- Network policies (Kubernetes)

### 5. Infrastructure as Code (IaC)

**Principe** : L'infrastructure est dÃ©finie en code, pas configurÃ©e manuellement.

**Exemple Terraform** :
```hcl
resource "aws_instance" "web" {
  count         = 10  # 10 instances crÃ©Ã©es automatiquement
  ami           = "ami-12345"
  instance_type = "t2.micro"
}
```

**Impact sur le routage** :
- Configuration rÃ©seau doit Ãªtre programmable
- APIs prioritaires sur CLI
- DÃ©claratif plutÃ´t qu'impÃ©ratif
- Versionnable et reproductible

## Architectures microservices : Besoins spÃ©cifiques

### Qu'est-ce qu'une architecture microservices ?

**Monolithe traditionnel** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Application Monolithique   â”‚
â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Auth   â”‚  â”‚ Paiement â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Catalog â”‚  â”‚  Panier  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚
â”‚  Tout dans un seul process   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Microservices** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Auth    â”‚â”€â”€â†’â”‚  Paiement  â”‚â”€â”€â†’â”‚ Notif.   â”‚
â”‚ Service  â”‚   â”‚  Service   â”‚   â”‚ Service  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“              â†“                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Catalog  â”‚â”€â”€â†’â”‚   Panier   â”‚â”€â”€â†’â”‚  Log     â”‚
â”‚ Service  â”‚   â”‚  Service   â”‚   â”‚ Service  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Chaque service est indÃ©pendant, dÃ©ployÃ© sÃ©parÃ©ment
```

**Analogie** :
- Monolithe = Grande entreprise avec tous les dÃ©partements dans un seul bÃ¢timent
- Microservices = RÃ©seau de petites entreprises spÃ©cialisÃ©es qui collaborent

### Besoins rÃ©seau des microservices

#### 1. Service Discovery (DÃ©couverte de services)

**ProblÃ¨me** : Comment Service A trouve-t-il Service B si B change d'IP constamment ?

**Solution traditionnelle (inadaptÃ©e)** :
```
Configuration en dur :
service_b_url = "http://192.168.1.50:8080"

ProblÃ¨me : Si le service B redÃ©marre â†’ nouvelle IP â†’ cassÃ© !
```

**Solution moderne : Service Registry** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service Registry   â”‚ â† Annuaire centralisÃ©
â”‚   (Consul, etcd)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘ â†“
    Register / Query
         â†‘ â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Service â”‚    â”‚Service â”‚
    â”‚   A    â”‚â”€â”€â”€â†’â”‚   B    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Processus :
1. Service B dÃ©marre â†’ S'enregistre avec son IP
2. Service A veut appeler B â†’ Interroge le registre
3. Registre rÃ©pond : "B est Ã  10.244.5.12:8080"
4. Service A appelle Service B
```

**Technologies** :
- **Consul** : Service discovery distribuÃ©
- **etcd** : Key-value store utilisÃ© par Kubernetes
- **ZooKeeper** : Coordination distribuÃ©e
- **Eureka** : Service discovery Netflix (Spring Cloud)

#### 2. Load Balancing intelligent

**Besoin** : Distribuer les requÃªtes entre plusieurs instances d'un service.

**Load Balancing L4 (Transport)** :
```
Client
  â†“
Load Balancer (IP/Port)
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API-1 â”‚ API-2 â”‚ API-3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

DÃ©cision basÃ©e sur : IP, Port, Round-robin
Simple mais limitÃ©
```

**Load Balancing L7 (Application)** :
```
Client
  â†“
API Gateway / Load Balancer
  â†“
Analyse la requÃªte HTTP
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GET /users â†’ Service Users      â”‚
â”‚ POST /orders â†’ Service Orders   â”‚
â”‚ GET /products â†’ Service Catalog â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DÃ©cision basÃ©e sur : URL, Headers, Cookies, MÃ©thode
Intelligent et flexible
```

**Algorithmes modernes** :
- **Round-robin** : Ã€ tour de rÃ´le
- **Least connections** : Instance la moins chargÃ©e
- **Weighted** : Selon capacitÃ© des instances
- **Latency-based** : Instance la plus rapide
- **Geographic** : Instance la plus proche

#### 3. Circuit Breakers

**ProblÃ¨me** : Si Service B est en panne, Service A ne doit pas continuer Ã  l'appeler.

**Sans Circuit Breaker** :
```
Service A appelle Service B (en panne)
â†“
Timeout aprÃ¨s 30 secondes
â†“
Retry
â†“
Timeout aprÃ¨s 30 secondes
â†“
...
RÃ©sultat : Service A devient lent, utilisateurs impactÃ©s
```

**Avec Circuit Breaker** :
```
Ã‰tats :
1. CLOSED (normal) : RequÃªtes passent
2. OPEN (panne dÃ©tectÃ©e) : RequÃªtes bloquÃ©es immÃ©diatement
3. HALF-OPEN (test) : Quelques requÃªtes pour tester la rÃ©cupÃ©ration

Service A â†’ [Circuit Breaker] â†’ Service B
                    â†“
            DÃ©tecte pannes
                    â†“
            Ouvre le circuit
                    â†“
        Ã‰chec immÃ©diat (pas d'attente)
                    â†“
        Fallback ou erreur gracieuse
```

**Analogie** : Le disjoncteur Ã©lectrique de votre maison
- Normalement fermÃ© (courant passe)
- DÃ©tecte surcharge â†’ S'ouvre automatiquement
- ProtÃ¨ge le reste de l'installation

#### 4. Retry et Backoff

**ProblÃ¨me** : Les requÃªtes peuvent Ã©chouer temporairement (rÃ©seau, charge).

**StratÃ©gie Retry avec Exponential Backoff** :
```
Tentative 1 : Ã‰choue â†’ Attendre 1 seconde
Tentative 2 : Ã‰choue â†’ Attendre 2 secondes
Tentative 3 : Ã‰choue â†’ Attendre 4 secondes
Tentative 4 : Ã‰choue â†’ Attendre 8 secondes
Tentative 5 : Abandon

Avantage : Ne surcharge pas le service dÃ©faillant
```

**Jitter (variation alÃ©atoire)** :
```
Au lieu de 1s, 2s, 4s, 8s exactement
Utilise : 1.2s, 1.8s, 4.3s, 7.6s

Pourquoi ? Ã‰viter que tous les clients retentent simultanÃ©ment
(phÃ©nomÃ¨ne de "thundering herd")
```

#### 5. Timeouts appropriÃ©s

**ProblÃ¨me** : Des timeouts mal configurÃ©s crÃ©ent des cascades de pannes.

**Mauvaise configuration** :
```
User â†’ API Gateway (timeout: 30s)
          â†“
       Service A (timeout: 30s)
          â†“
       Service B (timeout: 30s)
          â†“
       Service C (lent, 29s)

RÃ©sultat : User attend 30s, mais Service C rÃ©pond Ã  29s !
Pile d'attente se construit â†’ Cascade de pannes
```

**Bonne configuration** :
```
User â†’ API Gateway (timeout: 5s)
          â†“
       Service A (timeout: 3s)
          â†“
       Service B (timeout: 2s)
          â†“
       Service C (timeout: 1s)

Ã‰chec rapide Ã  chaque niveau
Circuit breaker peut intervenir
SystÃ¨me reste rÃ©actif
```

## Service Mesh : Le routage applicatif

### Qu'est-ce qu'un Service Mesh ?

Un **Service Mesh** est une couche d'infrastructure dÃ©diÃ©e pour gÃ©rer les communications service-Ã -service.

**Analogie** : Le systÃ¨me de contrÃ´le aÃ©rien
- Chaque avion (service) a son plan de vol
- La tour de contrÃ´le (control plane) supervise tout
- Les communications sont sÃ©curisÃ©es et tracÃ©es
- En cas de problÃ¨me, reroutage automatique

### Architecture d'un Service Mesh

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Control Plane (Istiod)          â”‚ â† Cerveau central
â”‚   - Configuration                       â”‚
â”‚   - Certificats                         â”‚
â”‚   - TÃ©lÃ©mÃ©trie                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ Configuration
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                   â†“         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Service Aâ”‚      â”‚Service Bâ”‚  â”‚Service Câ”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚      â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ App â”‚ â”‚      â”‚ â”‚ App â”‚ â”‚  â”‚ â”‚ App â”‚ â”‚
â”‚ â””â”€â”€â”¬â”€â”€â”˜ â”‚      â”‚ â””â”€â”€â”¬â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”¬â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â†“â”€â”€â”€â”â”‚      â”‚ â”Œâ”€â”€â†“â”€â”€â”€â”â”‚  â”‚ â”Œâ”€â”€â†“â”€â”€â”€â”â”‚
â”‚ â”‚Proxy â”‚â”‚â”€â”€â”€â”€â”€â†’â”‚ â”‚Proxy â”‚â”‚â”€â†’â”‚ â”‚Proxy â”‚â”‚ â† Data Plane
â”‚ â”‚(Envoyâ”‚â”‚      â”‚ â”‚(Envoyâ”‚â”‚  â”‚ â”‚(Envoyâ”‚â”‚   (Proxies)
â”‚ â””â”€â”€â”€â”€â”€â”€â”˜â”‚      â”‚ â””â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tout le trafic passe par les proxies (sidecar)
```

### FonctionnalitÃ©s d'un Service Mesh

#### 1. Traffic Management (Gestion du trafic)

**Routing sophistiquÃ©** :
```yaml
# Exemple Istio : Router 90% vers v1, 10% vers v2 (Canary deployment)
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: my-service
spec:
  hosts:
  - my-service
  http:
  - match:
    - headers:
        user-type:
          exact: beta-tester
    route:
    - destination:
        host: my-service
        subset: v2
      weight: 100
  - route:
    - destination:
        host: my-service
        subset: v1
      weight: 90
    - destination:
        host: my-service
        subset: v2
      weight: 10
```

**Cas d'usage** :
- **Canary deployments** : DÃ©ployer progressivement une nouvelle version
- **Blue/Green** : Basculer instantanÃ©ment entre versions
- **A/B testing** : Router selon les utilisateurs
- **Fault injection** : Injecter des erreurs pour tester la rÃ©silience

#### 2. Observability (ObservabilitÃ©)

**MÃ©triques automatiques** :
```
Pour chaque requÃªte entre services :
- Latence (p50, p95, p99)
- Taux d'erreur
- DÃ©bit (requÃªtes/seconde)
- Taille des rÃ©ponses

Sans modifier le code de l'application !
```

**Distributed Tracing** :
```
User Request â†’ Service A â†’ Service B â†’ Service C â†’ DB
      1ms         5ms        20ms       8ms      50ms
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 84ms total â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Visualisation :
[â–ˆâ–ˆâ–ˆâ–ˆ]â”€â”€â”€[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]â”€â”€â”€[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]â”€â”€â”€[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]â”€â”€â”€[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
  A         B             C          B           A

Permet d'identifier les bottlenecks
```

#### 3. Security (SÃ©curitÃ©)

**mTLS automatique** :
```
Sans Service Mesh :
Service A â†’ [PLAINTEXT] â†’ Service B
          â†‘ VulnÃ©rable au sniffing

Avec Service Mesh :
Service A â†’ [Proxy] â”€[TLS]â”€ [Proxy] â†’ Service B
                    â†‘
              ChiffrÃ© automatiquement
              Certificats gÃ©rÃ©s automatiquement
```

**Authentification et Autorisation** :
```yaml
# Seul Service A peut appeler Service B
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-service-a
spec:
  selector:
    matchLabels:
      app: service-b
  action: ALLOW
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/default/sa/service-a"]
```

### Service Mesh vs Protocoles de Routage traditionnels

| Aspect | Routage IP (OSPF/BGP) | Service Mesh |
|--------|----------------------|--------------|
| **Couche** | Couche 3 (RÃ©seau) | Couche 7 (Application) |
| **GranularitÃ©** | IP/Sous-rÃ©seau | Service/Version/Endpoint |
| **DÃ©cision** | Destination IP | URL, Headers, MÃ©thode |
| **SÃ©curitÃ©** | IPsec (optionnel) | mTLS par dÃ©faut |
| **ObservabilitÃ©** | NetFlow (limitÃ©) | MÃ©triques L7 complÃ¨tes |
| **Retry** | TCP uniquement | Logique mÃ©tier |
| **Circuit Breaking** | Non | Oui |
| **Canary** | Non | Natif |

**Conclusion** : Service Mesh complÃ¨te le routage IP, ne le remplace pas.

## Container Networking (Docker, Kubernetes)

### Docker Networking

**Modes de rÃ©seau Docker** :

#### 1. Bridge (par dÃ©faut)
```
Host Machine
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Docker Bridge (172.17.0.0/16)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ C1   â”‚  â”‚ C2   â”‚  â”‚ C3   â”‚    â”‚
â”‚  â”‚.0.2  â”‚  â”‚.0.3  â”‚  â”‚.0.4  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â†“ NAT                  â”‚
â”‚      [Host eth0]                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
      Internet

Conteneurs ont IPs privÃ©es
NAT pour accÃ¨s externe
Isolation entre conteneurs par dÃ©faut
```

#### 2. Host
```
Conteneur partage la stack rÃ©seau de l'hÃ´te
Pas d'isolation rÃ©seau
Performance maximale
Risques de sÃ©curitÃ©
```

#### 3. Overlay
```
Permet communication entre conteneurs sur hosts diffÃ©rents
Utilise VXLAN
NÃ©cessite Docker Swarm ou Ã©quivalent
```

### Kubernetes Networking

**ModÃ¨le rÃ©seau Kubernetes** :

```
Principes fondamentaux :
1. Chaque Pod a sa propre IP unique
2. Tous les Pods peuvent communiquer sans NAT
3. Tous les Nodes peuvent communiquer avec tous les Pods
```

**Architecture** :
```
Cluster Kubernetes
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node 1                    Node 2          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Pod A   â”‚             â”‚  Pod C   â”‚     â”‚
â”‚  â”‚10.244.1.2â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  â”‚10.244.2.5â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   Overlay   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Network  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Pod B   â”‚             â”‚  Pod D   â”‚     â”‚
â”‚  â”‚10.244.1.3â”‚             â”‚10.244.2.6â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Communication transparente entre tous les Pods
```

### CNI (Container Network Interface)

**Plugins CNI populaires** :

#### 1. Calico
- **Type** : Overlay ou routage BGP natif
- **Force** : Performance, politiques rÃ©seau avancÃ©es
- **Usage** : Production, scalabilitÃ©

```
Calico utilise BGP pour annoncer les routes des Pods !
Node 1 annonce : 10.244.1.0/24 est chez moi
Node 2 annonce : 10.244.2.0/24 est chez moi

Les protocoles de routage traditionnels servent encore !
```

#### 2. Flannel
- **Type** : Overlay VXLAN
- **Force** : SimplicitÃ©
- **Usage** : Petits clusters, dev/test

#### 3. Cilium
- **Type** : eBPF-based
- **Force** : Performance extrÃªme, sÃ©curitÃ©
- **Usage** : Clusters modernes, haute performance

#### 4. Weave Net
- **Type** : Overlay
- **Force** : Chiffrement natif
- **Usage** : Multi-cloud

### Services Kubernetes

**Abstraction au-dessus des Pods** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service "api"              â”‚ â† IP virtuelle stable
â”‚  ClusterIP: 10.96.10.20     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ Load balance
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
    â†“             â†“      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pod 1  â”‚  â”‚ Pod 2  â”‚  â”‚ Pod 3  â”‚ â† IPs Ã©phÃ©mÃ¨res
â”‚10.244. â”‚  â”‚10.244. â”‚  â”‚10.244. â”‚
â”‚  1.5   â”‚  â”‚  2.8   â”‚  â”‚  3.2   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Clients appellent le Service (IP stable)
Service route vers les Pods (IPs changeantes)
```

**Types de Services** :

| Type | Description | Cas d'usage |
|------|-------------|-------------|
| **ClusterIP** | IP interne au cluster | Communication interne |
| **NodePort** | Port sur chaque Node | AccÃ¨s depuis l'extÃ©rieur |
| **LoadBalancer** | Load balancer externe | Production (cloud) |
| **ExternalName** | Alias DNS | Services externes |

### Ingress : Routage HTTP/HTTPS

**ProblÃ¨me** : Exposer plusieurs services HTTP via une seule IP.

**Solution : Ingress Controller** :
```
                 Internet
                    â†“
            [Load Balancer]
                    â†“
            [Ingress Controller]
                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                               â†“
api.example.com              web.example.com
    â†“                               â†“
[Service API]                [Service Web]
    â†“                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pod A  â”‚                    â”‚ Pod W  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Routage basÃ© sur :
- Hostname (api.example.com vs web.example.com)
- Path (/api vs /web)
- Headers
```

**Exemple de configuration Ingress** :
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: example-ingress
spec:
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 80
  - host: web.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80
```

## Overlay Networks et Encapsulation

### Qu'est-ce qu'un Overlay Network ?

Un **overlay network** est un rÃ©seau virtuel construit **au-dessus** d'un rÃ©seau physique existant.

**Analogie** : Les tunnels autoroutiers
- L'autoroute physique existe (underlay)
- Le tunnel crÃ©e un chemin virtuel au-dessus (overlay)
- Les voitures dans le tunnel ignorent la structure physique en dessous

### VXLAN (Virtual Extensible LAN)

**Principe** : Encapsuler des trames Ethernet dans des paquets UDP.

**Encapsulation** :
```
Paquet original :
[Ethernet Header][IP Header][TCP][Data]

AprÃ¨s encapsulation VXLAN :
[Outer Ethernet][Outer IP][UDP][VXLAN][Ethernet Header][IP Header][TCP][Data]
                               â†‘
                         VNI = 5000

Le paquet original est "tunnelisÃ©" dans UDP
```

**Avantages** :
- **24-bit VNI** : 16 millions de rÃ©seaux virtuels (vs 4096 VLANs)
- **Overlay** : Fonctionne sur n'importe quel rÃ©seau IP
- **Multi-tenancy** : Isolation complÃ¨te entre tenants
- **ScalabilitÃ©** : Supporte cloud Ã  grande Ã©chelle

**Exemple d'utilisation** :
```
Datacenter physique (Underlay) : 10.0.0.0/8
    â†“
VXLAN Overlay Networks :
- Tenant A : VNI 1000, utilise 192.168.0.0/16
- Tenant B : VNI 2000, utilise 192.168.0.0/16 (mÃªme espace !)
- Tenant C : VNI 3000, utilise 10.0.0.0/16

Pas de conflit, isolation complÃ¨te
```

### Comparaison Underlay vs Overlay

| Aspect | Underlay | Overlay |
|--------|----------|---------|
| **DÃ©finition** | RÃ©seau physique | RÃ©seau virtuel |
| **Protocoles** | OSPF, BGP | VXLAN, GRE, IPsec |
| **RÃ´le** | ConnectivitÃ© de base | Isolation et flexibilitÃ© |
| **Visible par** | Admins rÃ©seau | Admins cloud/applicatif |
| **Exemple** | Switches, routeurs physiques | Kubernetes network, AWS VPC |

**Relation** :
```
     Applications
          â†“
    Overlay Network (VXLAN)
          â†“
    Underlay Network (OSPF/BGP)
          â†“
  Infrastructure physique
```

## Routage multi-cloud et hybride

### DÃ©fis du multi-cloud

**ScÃ©nario** :
```
Application distribuÃ©e :
- Frontend : AWS
- Backend : Google Cloud
- Database : Azure
- On-premise : Datacenter entreprise

Comment router efficacement entre tous ces environnements ?
```

**ProblÃ¨mes** :
- Espaces d'adressage potentiellement conflictuels
- Latence entre clouds
- CoÃ»ts de transfert de donnÃ©es (egress)
- ComplexitÃ© de configuration
- SÃ©curitÃ© et chiffrement

### Solutions de connectivitÃ©

#### 1. VPN Site-to-Site
```
AWS VPC â”€â”€â”€â”€â”€[VPN]â”€â”€â”€â”€â”€ Azure VNet
   â†‘                       â†‘
   â””â”€â”€â”€â”€[VPN]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†‘
      On-premise DC

Avantages : Simple, chiffrÃ©
InconvÃ©nients : Latence, dÃ©bit limitÃ©, sur Internet public
```

#### 2. Direct Connect / ExpressRoute
```
AWS â”€â”€â”€â”€â”€[Fiber privÃ©e]â”€â”€â”€â”€â”€ Azure
                â†“
          On-premise DC

Avantages : Bande passante Ã©levÃ©e, latence faible, SLA
InconvÃ©nients : CoÃ»teux, setup complexe
```

#### 3. SD-WAN
```
        SD-WAN Controller
               â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                     â†“
AWS Branch           Azure Branch
    â†“                     â†“
 Internet / MPLS / 5G (multiple paths)
    â†“                     â†“
On-premise DC

Avantages : Intelligent, multi-path, application-aware
```

### BGP dans le cloud

**Utilisation de BGP** :

```
Cas 1 : AWS Direct Connect
- Vous annoncez vos prÃ©fixes on-premise Ã  AWS via BGP
- AWS annonce ses prÃ©fixes Ã  vous
- Routage dynamique entre on-premise et cloud

Cas 2 : Google Cloud Router
- Utilise BGP pour les VPN dynamiques
- Apprend automatiquement les routes
- Convergence rapide

Cas 3 : Azure ExpressRoute
- BGP pour Ã©changer les routes
- Support de communautÃ©s BGP
- ContrÃ´le du trafic
```

**Exemple de configuration** :
```
router bgp 65001
  neighbor 169.254.1.1 remote-as 64512  ! AWS ASN
  neighbor 169.254.1.1 description AWS-DirectConnect

  network 10.0.0.0 mask 255.255.0.0     ! Annonce rÃ©seau on-prem

  ! PrÃ©fÃ©rer Direct Connect sur VPN
  neighbor 169.254.1.1 route-map PREFER-DC in

route-map PREFER-DC permit 10
  set local-preference 200
```

## Tendances et Ã©volutions futures

### 1. eBPF et programmabilitÃ© du noyau

**eBPF (extended Berkeley Packet Filter)** : Permet d'exÃ©cuter du code dans le noyau Linux sans modifier le noyau.

**Impact sur le networking** :
- Performance : Bypass du kernel network stack
- ObservabilitÃ© : TraÃ§age au niveau paquet
- SÃ©curitÃ© : Firewall ultra-rapide
- Load balancing : Directement dans le kernel

**Exemple : Cilium** :
```
Routage traditionnel :
Paquet â†’ Kernel â†’ iptables (lent) â†’ Application

Avec eBPF :
Paquet â†’ eBPF (noyau) â†’ Application
         â†‘ 10Ã— plus rapide !
```

### 2. Service Mesh sans sidecar

**ProblÃ¨me actuel** : Chaque pod a un proxy sidecar (overhead mÃ©moire/CPU).

**Solution Ã©mergente : Ambient Mesh** (Istio) :
```
Au lieu de :
â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚App+  â”‚  â”‚App+  â”‚  â”‚App+  â”‚
â”‚Proxy â”‚  â”‚Proxy â”‚  â”‚Proxy â”‚
â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜

Nouveau modÃ¨le :
â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”
â”‚ App â”‚  â”‚ App â”‚  â”‚ App â”‚
â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜
    â†“       â†“       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Shared Layer 4 Proxy    â”‚ â† Node-level
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Moins de ressources, mÃªme fonctionnalitÃ©s
```

### 3. IPv6 adoption dans le cloud

**Ã‰tat actuel** : MajoritÃ© des clouds utilisent IPv4 en interne avec NAT.

**Tendance** :
- AWS, GCP, Azure supportent IPv6
- Kubernetes IPv6 en production
- Simplification (pas de NAT nÃ©cessaire)
- ScalabilitÃ© illimitÃ©e

**DÃ©fis** :
- Migration complexe
- Outils pas tous prÃªts
- Formation des Ã©quipes

### 4. Edge Computing

**Principe** : Rapprocher le compute des utilisateurs.

```
          Cloud Central
               â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                     â†“
Edge Location 1      Edge Location 2
    â†“                     â†“
Utilisateurs          Utilisateurs

Latence : 5-10ms au lieu de 50-100ms
```

**Implications rÃ©seau** :
- Anycast (mÃªme IP, multiples locations)
- BGP pour router vers le plus proche
- Service mesh distribuÃ© gÃ©ographiquement
- Synchronisation des donnÃ©es entre edges

### 5. Zero Trust Networking

**Principe** : "Ne jamais faire confiance, toujours vÃ©rifier"

**Architecture traditionnelle** :
```
Firewall pÃ©rimÃ©trique
    â†“
[Zone de confiance interne] â† Tout est permis
    â†“
Serveurs communiquent librement
```

**Zero Trust** :
```
Chaque communication est :
- AuthentifiÃ©e
- AutorisÃ©e
- ChiffrÃ©e
- AuditÃ©e

MÃªme Ã  l'intÃ©rieur du rÃ©seau !
```

**Technologies** :
- Service mesh avec mTLS
- Microsegmentation
- Identity-based access (pas IP-based)
- Network policies strictes

### 6. Intent-Based Networking

**Principe** : DÃ©crire ce que vous voulez, pas comment le faire.

**Ancien modÃ¨le** :
```
"Configure VLAN 10 sur port Gi0/1 avec QoS..."
(ImpÃ©ratif, technique)
```

**Nouveau modÃ¨le** :
```
"Je veux que Service A communique avec Service B
avec latence < 10ms et 99.9% de disponibilitÃ©"
(DÃ©claratif, mÃ©tier)

Le systÃ¨me dÃ©termine automatiquement la configuration
```

**Technologies** :
- Cisco DNA Center
- VMware NSX Intelligence
- Google Anthos Config Management

### 7. AI/ML pour le routage

**Applications** :
- **PrÃ©diction de pannes** : ML dÃ©tecte patterns anormaux
- **Optimisation dynamique** : Ajustement des routes selon ML
- **Anomaly detection** : DÃ©tection d'attaques ou bugs
- **Capacity planning** : PrÃ©vision des besoins

**Exemple** :
```
SystÃ¨me ML analyse :
- Patterns de trafic historiques
- Performance des chemins
- PrÃ©visions mÃ©tÃ©o (impact sur liens sans fil)
- Ã‰vÃ©nements (Black Friday)

â†’ Ajuste automatiquement le routage
â†’ Provisionne des ressources en avance
```

## Bonnes pratiques pour architectures cloud

### 1. Design for failure

**Principe** : Tout va tomber en panne, prÃ©parez-vous.

```
âœ… Faire :
- Multi-zone (AZ)
- Load balancers avec health checks
- Circuit breakers
- Retry avec backoff
- Timeouts appropriÃ©s

âŒ Ã‰viter :
- Single point of failure
- Supposer que le rÃ©seau est fiable
- Timeouts infinis
```

### 2. Observability is key

**Les 3 piliers** :
- **Logs** : Ã‰vÃ©nements discrets
- **Metrics** : DonnÃ©es numÃ©riques agrÃ©gÃ©es
- **Traces** : Suivi de requÃªtes distribuÃ©es

**Tooling** :
```
Logs : ELK Stack, Loki
Metrics : Prometheus, Datadog
Traces : Jaeger, Zipkin, AWS X-Ray

CorrÃ©lation entre les 3 = ComprÃ©hension complÃ¨te
```

### 3. Automatisation et IaC

**Infrastructure as Code** :
```yaml
# Terraform : RÃ©seau complet en code
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
}

resource "aws_subnet" "public" {
  vpc_id     = aws_vpc.main.id
  cidr_block = "10.0.1.0/24"
}

# VersionnÃ© dans Git
# Reproductible
# Testable
```

### 4. SÃ©curitÃ© par dÃ©faut

```
Principes :
- mTLS entre tous les services (service mesh)
- Network policies restrictives (deny by default)
- Chiffrement en transit ET au repos
- Rotation automatique des secrets
- Audit logging
```

### 5. Progressive rollouts

**DÃ©ploiements progressifs** :
```
1. Canary : 5% trafic â†’ nouvelle version
2. Observer mÃ©triques (erreurs, latence)
3. Si OK : 25% â†’ 50% â†’ 100%
4. Si KO : Rollback automatique

Minimise l'impact des bugs en production
```

## Points clÃ©s Ã  retenir

1. **Le cloud change tout** : Infrastructure Ã©phÃ©mÃ¨re, Ã©chelle massive, dynamicitÃ© extrÃªme
2. **Protocoles traditionnels restent pertinents** : Underlay utilise OSPF/BGP
3. **Overlay networks** : VXLAN pour isolation et multi-tenancy
4. **Service discovery** : Essentiel pour microservices (Consul, etcd)
5. **Service mesh** : Routage L7, sÃ©curitÃ©, observabilitÃ© (Istio, Linkerd)
6. **Load balancing Ã©volue** : De L4 vers L7, intelligence applicative
7. **Est-Ouest domine** : 75% du trafic entre services, pas vers Internet
8. **Observability critique** : Traces distribuÃ©es, mÃ©triques L7
9. **Zero Trust** : SÃ©curitÃ© Ã  chaque hop, mÃªme interne
10. **Automatisation obligatoire** : IaC, GitOps, pas de configuration manuelle
11. **Design for failure** : Circuit breakers, retry, timeouts
12. **Kubernetes networking** : CNI, Services, Ingress abstraient la complexitÃ©
13. **Multi-cloud** : BGP, VPN, SD-WAN pour interconnexion
14. **Tendances** : eBPF, ambient mesh, intent-based networking, AI/ML

## Conclusion de la section sur les protocoles de routage

Nous avons maintenant complÃ©tÃ© notre exploration des protocoles de routage, de RIP simple Ã  BGP complexe, jusqu'aux architectures cloud modernes.

**Le voyage** :
```
3.12.1 : Routage statique vs dynamique
         â†“
3.12.2 : RIP (vecteur de distance, simple)
         â†“
3.12.3 : OSPF (Ã©tat de lien, entreprise)
         â†“
3.12.4 : BGP (Internet, politique)
         â†“
3.12.5 : MÃ©triques et convergence
         â†“
3.12.6 : Cloud et microservices (vous Ãªtes ici !)
```

**L'Ã©volution du routage** :
- **1980s** : Routage statique
- **1990s** : RIP, OSPF (automatisation)
- **2000s** : BGP mature (Internet global)
- **2010s** : SDN, overlay networks (virtualisation)
- **2020s** : Service mesh, eBPF (cloud-native)

**Message final** : Les protocoles de routage classiques (OSPF, BGP) ne sont pas obsolÃ¨tes. Ils alimentent l'underlay sur lequel tout le cloud fonctionne. Les technologies modernes (Service Mesh, Kubernetes) ajoutent des couches d'abstraction, mais reposent sur ces fondations solides.

Comprendre Ã  la fois les protocoles traditionnels ET les architectures modernes vous donne une vision complÃ¨te du networking, du paquet IP qui traverse un routeur aux requÃªtes HTTP qui naviguent dans un service mesh.

---

**Conseil pratique** : Si vous dÃ©butez dans le cloud, ne sautez pas l'apprentissage des bases (OSPF, BGP). Ces concepts se retrouvent partout : Calico utilise BGP, les clouds utilisent OSPF/BGP en interne, les architectures multi-cloud nÃ©cessitent BGP. Construisez d'abord des fondations solides en networking traditionnel, puis explorez le cloud - vous comprendrez mieux comment tout s'articule et pourquoi certains choix ont Ã©tÃ© faits !

â­ï¸ [4. La couche Transport](/04-couche-transport/README.md)
